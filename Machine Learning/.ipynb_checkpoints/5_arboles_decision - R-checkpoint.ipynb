{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los Arboles de Decision son diagramas con construcciones lógicas, muy similares a los sistemas de predicción basados en reglas, que sirven para representar y categorizar una serie de condiciones que ocurren de forma sucesiva, para la resolución de un problema. Los Arboles de Decision están compuestos por nodos interiores, nodos terminales y ramas que emanan de los nodos interiores. Cada nodo interior en el árbol contiene una prueba de un atributo, y cada rama representa un valor distinto del atributo. Siguiendo las ramas desde el nodo raíz hacia abajo, cada ruta finalmente termina en un nodo terminal creando una segmentación de los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas razones de aprender arboles de decisión:\n",
    "- Son útiles tanto para problemas de regresión como de clasificación.\n",
    "- Son populares.\n",
    "- Son la base de enfoques de modelado más sofisticados.\n",
    "- Demuestran una forma diferente de \"pensar\" que los modelos que hemos estudiado hasta ahora.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprender mejor el concepto de árbol de decisión, supongamos que Nuestra meta es predecir el Salario de un jugador de béisbol basado en Años (número de años jugando en las ligas mayores) e Hits (número de golpes que hizo el año anterior). Aquí están los datos de la formación, representados visualmente (el salario bajo es azul/verde, el alto es rojo/amarillo):<br>\n",
    "\n",
    "Datos de los jugadores de las Grandes Ligas de Béisbol de 1986-87: <br>\n",
    "\n",
    "Años (eje x): número de años jugando en las ligas mayores.<br>\n",
    "Hits (eje y): número de impactos en el año anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![beisol_arbol](img/beisol_arbol.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio en grupo:<br>\n",
    "Los datos anteriores son nuestros datos de formación.<br>\n",
    "Queremos construir un modelo que prediga el Salario de los futuros jugadores basado en Años y Hits.<br>\n",
    "Vamos a \"segmentar\" el espacio de características en regiones, y luego usar el Salario medio en cada región como el Salario predicho para futuros jugadores.<br>\n",
    "Intuitivamente, usted quiere maximizar la similitud (u \"homogeneidad\") dentro de una región dada, y minimizar la similitud entre diferentes regiones.<br>\n",
    "Reglas de segmentación:\n",
    "- Sólo se pueden utilizar líneas rectas, dibujadas de una en una.\n",
    "- Su línea debe ser vertical u horizontal.\n",
    "- Su línea se detiene cuando choca con una línea existente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se muestra un árbol de regresión que ha sido ajustado a los datos por una computadora. (Hablaremos más adelante sobre cómo funciona realmente el algoritmo de adaptación.) Tenga en cuenta que el salario se mide en miles y se ha transformado en registros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![arbol_computadora](img/arbol_computadora.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empiece por arriba y examine la primera \"regla de partición\" (Años < 4,5).<br>\n",
    "Si la regla es True para un jugador dado, sigue la rama izquierda. Si la regla es Falsa, siga la rama derecha.<br>\n",
    "Continúe hasta llegar al fondo. El Salario predicho es el número en ese \"cubo\" en particular.<br>\n",
    "Nota: Los Años y los Hits son ambos enteros, pero la convención es etiquetar estas reglas usando el punto medio entre valores adyacentes.<br>\n",
    "Ejemplo de predicciones:\n",
    "- 3 años, entonces se predice 5.11($ 1000 x e5.11 ~ $166000)\n",
    "- 5 años y 100 hits, entonces se predice 6.00($ 1000 x e6.00 ~ $403000)\n",
    "- 8 años y 120 hits, entonces se predice 6.74($ 1000 x e6.74 ~ $846000)\n",
    "\n",
    "¿Cómo se nos ocurrieron los números de la parte inferior del árbol? <br>Cada número es sólo el salario medio en los datos de entrenamiento de los jugadores que cumplen con ese criterio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí está el mismo diagrama que antes, dividido en las tres regiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![arbol_region](img/arbol_region.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este diagrama es esencialmente una combinación de los dos diagramas anteriores. En R1, el salario medio del registro fue de 5.11. En R2, el salario medio del registro fue de 6.00. En R3, el salario medio del registro fue de 6.74. Por lo tanto, esos valores se utilizan para predecir datos fuera de la muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a introducir algo de terminología:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![terminologia_arbol](img/salary_tree_annotated.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo podría interpretar el \"significado\" de este árbol?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los Años son el factor más importante que determina el Salario, con un menor número de Años que corresponden a un Salario más bajo.<br>\n",
    "Para un jugador con un número menor de Años, los Impactos no son un factor importante para determinar el Salario.<br>\n",
    "Para un jugador con un número mayor de Años, los Impactos son un factor importante que determina el Salario, con un mayor número de Impactos que corresponde a un Salario mayor.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hemos visto hasta ahora indica las ventajas y desventajas de los árboles de decisión:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Altamente interpretable\n",
    "- Puede visualizarse gráficamente\n",
    "- La predicción es rápida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desventajas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La precisión predictiva no es tan alta como algunos métodos de aprendizaje supervisado\n",
    "- Puede fácilmente sobredimensionar los datos de entrenamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de árbol de regresión con scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setwd(\"D:/iush2020/Mineria de datos/notebooks/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- read.csv('https://raw.githubusercontent.com/justmarkham/DAT5/master/data/vehicles_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train$type <- ifelse(train$type == \"car\",0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[,2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[1:11,]\n",
    "X_test = X[12:14,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[1:11]\n",
    "y_test = y[12:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treereg = tree(price ~ + year + miles + doors + type, data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(treereg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creando el diagrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(treereg)\n",
    "text(treereg, pretty = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Nodos internos:</b><br>\n",
    "\n",
    "\"muestras\" es el número de observaciones en ese nodo antes de la división<br>\n",
    "\"mse\" es el error cuadrático medio calculado comparando los valores reales de respuesta en ese nodo con el valor medio de respuesta en ese nodo.<br>\n",
    "primera línea es la condición usada para dividir ese nodo (ir a la izquierda si es verdadero, ir a la derecha si es falso)<br>\n",
    "\n",
    "<b>Hojas:</b>\n",
    "\n",
    "\"muestras\" es el número de observaciones en ese nodo<br>\n",
    "\"valor\" es el valor medio de la respuesta en ese nodo<br>\n",
    "\"mse\" es el error cuadrático medio calculado comparando los valores reales de respuesta en ese nodo con \"valor\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probando el modelo con datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- read.csv('https://raw.githubusercontent.com/justmarkham/DAT5/master/data/vehicles_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train$type <- ifelse(train$type == \"car\",0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[,2:5]\n",
    "y = train[,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediciones = predict(object = treereg, newdata = X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arboles de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los árboles de clasificación son muy similares a los árboles de regresión. He aquí una rápida comparación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|árboles de regresión|árboles de clasificación|\n",
    "      |---|---|\n",
    "      |predecir una respuesta continua|predecir una respuesta categórica|\n",
    "      |predecir usando la respuesta media de cada hoja |predecir usando la clase más común de cada hoja|\n",
    "      |las divisiones se eligen para minimizar MSE|las divisiones se eligen para minimizar el índice de Gini (discutido a continuación)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criterios de partición para árboles de clasificación<br>\n",
    "A continuación, se presentan opciones comunes para los criterios de partición:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tasa de error de clasificación: fracción de las observaciones de entrenamiento en una región que no pertenece a la clase más común\n",
    "- Índice de Gini: medida de la varianza total entre clases en una región\n",
    "- centropía cruzada: numéricamente similar al índice de Gini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de la división es aumentar la \"pureza del nodo\", y resulta que el índice de Gini y la cruzentropía son mejores medidas de pureza que la tasa de error de clasificación. El índice de Gini es más rápido de calcular que el de centrocross, por lo que generalmente es el preferido (y es usado por scikit-learn por defecto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos de cálculos del índice de Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digamos que estamos prediciendo la supervivencia en el Titanic. En un nodo en particular, hay 25 individuos, de los cuales 10 sobrevivieron y 15 murieron. Así es como calculamos el índice de Gini antes de hacer una división:<br>\n",
    "\n",
    "![gini](img/math1.svg)\n",
    "\n",
    "\n",
    "El valor máximo del índice Gini es de 0,5, y se produce cuando las clases están perfectamente equilibradas en un nodo. El valor mínimo del índice Gini es 0, y ocurre cuando sólo hay una clase representada en un nodo. Así, un nodo con un índice de Gini más bajo se dice que es más \"puro\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al decidir entre particiones, el algoritmo del árbol de decisión elige la partición que maximiza la pureza del nodo resultante. Supongamos que el género fue la división que se está considerando, y los nodos resultantes son los siguientes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hombres: 2 sobrevivieron, 13 murieron<br>\n",
    "Hembras: 8 sobrevivieron, 2 murieron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar esta división, calculamos el promedio ponderado de los índices de Gini de los nodos resultantes:<br>\n",
    "\n",
    "![gini](img/math2.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, la disminución del índice de Gini (y el aumento de la pureza) a partir de la división en sexos es de 0,21. El algoritmo del árbol de decisión elegirá esta división si ninguna otra división resulta en una mayor ganancia en pureza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de árbol de clasificación en scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic <- read.csv('https://raw.githubusercontent.com/justmarkham/DAT5/master/data/titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elijamos nuestra variable de respuesta y algunas características, y repasemos cómo manejar las características categóricas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobrevivió: Esta es nuestra variable de respuesta, y ya está codificada como 0=muerto y 1=vivo.<br>\n",
    "Clase P: Estas son las categorías de clase de pasajeros (1=primera clase, 2=segunda clase, 3=tercera clase). Están ordenados lógicamente, así que los dejaremos como están. (Si el árbol se divide en esta característica, las divisiones ocurrirán en 1.5 o 2.5.)<br>\n",
    "Sexo: Esta es una categoría binaria, por lo que debemos codificarla como 0=mujer y 1=hombre. (Si el árbol se divide en esta característica, la división ocurrirá en 0.5.)<br>\n",
    "Edad: Esta es una característica numérica, pero necesitamos rellenar los valores que faltan.<br>\n",
    "Embarcado: Este es el puerto de donde salieron. Hay tres categorías desordenadas, así que debemos crear variables ficticias y dejar caer un nivel como de costumbre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode female as 0 and male as 1\n",
    "titanic$Sex <- ifelse(titanic$Sex == \"female\",0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the missing values for age with the mean age\n",
    "titanic$Age <- ifelse(is.na(titanic$Age), mean(titanic$Age, na.rm=TRUE), titanic$Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create three dummy variables, drop the first dummy variable, and store the two remaining columns as a DataFrame\n",
    "install.packages(\"dummies\")\n",
    "library(dummies)\n",
    "titanic_dummy = dummy.data.frame(titanic, names = c(\"Embarked\") , sep = \".\")\n",
    "titanic_dummy = titanic_dummy[,0:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_x = titanic_dummy[,c(\"Survived\",\"Pclass\", \"Sex\", \"Age\", \"Embarked.C\", \"Embarked.Q\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_x$Survived <- ifelse(titanic_x$Survived == 1, \"Vivo\", \"Muerto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_x$Survived = as.factor(titanic_x$Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(titanic_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = titanic_x[1:600,]\n",
    "X_test = titanic_x[601:891,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeclf = tree(Survived ~ ., data = X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = predict(object = treeclf, newdata = X_test, type = \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(treeclf)\n",
    "text(treeclf, pretty = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(predicciones, X_test$Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(178+57)/290"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He aquí algunas ventajas y desventajas de los árboles de decisión de los que aún no hemos hablado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pueden especificarse como una serie de reglas, y se piensa que se aproximan más a la toma de decisiones humanas que otros modelos.\n",
    "- Altamente interpretables incluso mas que la regresion lineal\n",
    "- Pueden ser utilizados para regresion o clasificacion\n",
    "- Puede visualizarse gráficamente\n",
    "- Tiende a ignorar características irrelevantes\n",
    "- Las funciones no necesitan escalado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desventajas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El rendimiento (generalmente) no es competitivo con los mejores métodos de aprendizaje supervisado\n",
    "- Puede fácilmente sobredimensionar los datos de entrenamiento (se requiere afinación)\n",
    "- Pequeñas variaciones en los datos pueden resultar en un árbol completamente diferente (alta varianza)\n",
    "- La división binaria recurrente toma decisiones \"localmente óptimas\" que pueden no resultar en un árbol globalmente óptimo.\n",
    "- No suele funcionar bien si las clases están muy desequilibradas\n",
    "- No tiende a funcionar bien con conjuntos de datos muy pequeños\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es de resaltar que existe variantes del algoritmo de árbol de decisión: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algoritmos por particionamiento: \n",
    "    \n",
    "- C4.5\n",
    "- CART\n",
    "- ID3\n",
    "- CHAID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests (Bosques aleatorios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por que no utilizar un cojunto de arboles para predecir. Esta es la idea detras de Random Forest, la combinacion de multiples arboles de decision. <br>\n",
    "los bosques aleatorios han ganado gran popularidad y acogida por la comunidad practicante de aprendizaje automatico debido a su buen rendimiento en tareas de clasificacion, escalabilidad y facilidad de uso. Los arboles aleatorios promedian multiples arboles de decision(profundos) que sufren indivudualmente una alta varianza, para construir un modelo mas robusto que sea menos suceptible a tener sobre ajuste y por consiguiente tenga mejor rendimiento o generalizacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Es una tecnica de aprendizaje en conjunto  o ensamble learning, tecnica muy poderosa y con mucha popularidad en consursos de aprendizaje automatico.<br>\n",
    "Se basa en la salida de muchos modelos individuales que combinan dichas salidas de una manera inteligente para producir un modelo de aprendizaje automatico mas fuerte y robusto.<br>\n",
    "El aprendizaje en conjunto funciona mejor cuando los modelos individuales que componen el conjunto son tan diferentes entre sí como sea posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmos por cobertura:\n",
    "- AQ\n",
    "- CN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"randomForest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bosque = randomForest(Survived ~ ., data = X_train, ntree = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = predict(object = bosque, newdata = X_test, type = \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(predicciones, X_test$Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance(bosque)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ventajas de los bosques aleatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El rendimiento es competitivo con los mejores métodos de aprendizaje supervisado\n",
    "- Proporciona una estimación más fiable de la importancia de las características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Menos interpretable\n",
    "- Más lento para entrenar\n",
    "- Más lento de predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
