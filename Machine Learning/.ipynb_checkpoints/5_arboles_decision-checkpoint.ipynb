{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los Arboles de Decision son diagramas con construcciones lógicas, muy similares a los sistemas de predicción basados en reglas, que sirven para representar y categorizar una serie de condiciones que ocurren de forma sucesiva, para la resolución de un problema. Los Arboles de Decision están compuestos por nodos interiores, nodos terminales y ramas que emanan de los nodos interiores. Cada nodo interior en el árbol contiene una prueba de un atributo, y cada rama representa un valor distinto del atributo. Siguiendo las ramas desde el nodo raíz hacia abajo, cada ruta finalmente termina en un nodo terminal creando una segmentación de los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas razones de aprender arboles de decisión:\n",
    "- Son útiles tanto para problemas de regresión como de clasificación.\n",
    "- Son populares.\n",
    "- Son la base de enfoques de modelado más sofisticados.\n",
    "- Demuestran una forma diferente de \"pensar\" que los modelos que hemos estudiado hasta ahora.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprender mejor el concepto de árbol de decisión, supongamos que Nuestra meta es predecir el Salario de un jugador de béisbol basado en Años (número de años jugando en las ligas mayores) e Hits (número de golpes que hizo el año anterior). Aquí están los datos de la formación, representados visualmente (el salario bajo es azul/verde, el alto es rojo/amarillo):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![beisol_arbol](img/beisol_arbol.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio en grupo:<br>\n",
    "Los datos anteriores son nuestros datos de formación.<br>\n",
    "Queremos construir un modelo que prediga el Salario de los futuros jugadores basado en Años y Hits.<br>\n",
    "Vamos a \"segmentar\" el espacio de características en regiones, y luego usar el Salario medio en cada región como el Salario predicho para futuros jugadores.<br>\n",
    "Intuitivamente, usted quiere maximizar la similitud (u \"homogeneidad\") dentro de una región dada, y minimizar la similitud entre diferentes regiones.<br>\n",
    "Reglas de segmentación:\n",
    "- Sólo se pueden utilizar líneas rectas, dibujadas de una en una.\n",
    "- Su línea debe ser vertical u horizontal.\n",
    "- Su línea se detiene cuando choca con una línea existente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se muestra un árbol de regresión que ha sido ajustado a los datos por una computadora. (Hablaremos más adelante sobre cómo funciona realmente el algoritmo de adaptación.) Tenga en cuenta que el salario se mide en miles y se ha transformado en registros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![arbol_computadora](img/arbol_computadora.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empiece por arriba y examine la primera \"regla de partición\" (Años < 4,5).<br>\n",
    "Si la regla es True para un jugador dado, sigue la rama izquierda. Si la regla es Falsa, siga la rama derecha.<br>\n",
    "Continúe hasta llegar al fondo. El Salario predicho es el número en ese \"cubo\" en particular.<br>\n",
    "Nota: Los Años y los Hits son ambos enteros, pero la convención es etiquetar estas reglas usando el punto medio entre valores adyacentes.<br>\n",
    "Ejemplo de predicciones:\n",
    "- 3 años, entonces se predice 5.11($ 1000 x e5.11 ~ $166000)\n",
    "- 5 años y 100 hits, entonces se predice 6.00($ 1000 x e6.00 ~ $403000)\n",
    "- 8 años y 120 hits, entonces se predice 6.74($ 1000 x e6.74 ~ $846000)\n",
    "\n",
    "¿Cómo se nos ocurrieron los números de la parte inferior del árbol? Cada número es sólo el salario medio en los datos de entrenamiento de los jugadores que cumplen con ese criterio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí está el mismo diagrama que antes, dividido en las tres regiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![arbol_region](img/arbol_region.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este diagrama es esencialmente una combinación de los dos diagramas anteriores. En R1, el salario medio del registro fue de 5.11. En R2, el salario medio del registro fue de 6.00. En R3, el salario medio del registro fue de 6.74. Por lo tanto, esos valores se utilizan para predecir datos fuera de la muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a introducir algo de terminología:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![terminologia_arbol](img/terminologia_arbol.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo podría interpretar el \"significado\" de este árbol?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los Años son el factor más importante que determina el Salario, con un menor número de Años que corresponden a un Salario más bajo.<br>\n",
    "Para un jugador con un número menor de Años, los Impactos no son un factor importante para determinar el Salario.<br>\n",
    "Para un jugador con un número mayor de Años, los Impactos son un factor importante que determina el Salario, con un mayor número de Impactos que corresponde a un Salario mayor.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hemos visto hasta ahora indica las ventajas y desventajas de los árboles de decisión:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Altamente interpretable\n",
    "- Puede visualizarse gráficamente\n",
    "- La predicción es rápida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desventajas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La precisión predictiva no es tan alta como algunos métodos de aprendizaje supervisado\n",
    "- Puede fácilmente sobredimensionar los datos de entrenamiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de árbol de regresión con scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT5/master/data/vehicles_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>miles</th>\n",
       "      <th>doors</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22000</td>\n",
       "      <td>2012</td>\n",
       "      <td>13000</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14000</td>\n",
       "      <td>2010</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13000</td>\n",
       "      <td>2010</td>\n",
       "      <td>73500</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9500</td>\n",
       "      <td>2009</td>\n",
       "      <td>78000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000</td>\n",
       "      <td>2007</td>\n",
       "      <td>47000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4000</td>\n",
       "      <td>2006</td>\n",
       "      <td>124000</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000</td>\n",
       "      <td>2004</td>\n",
       "      <td>177000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000</td>\n",
       "      <td>2004</td>\n",
       "      <td>209000</td>\n",
       "      <td>4</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3000</td>\n",
       "      <td>2003</td>\n",
       "      <td>138000</td>\n",
       "      <td>2</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1900</td>\n",
       "      <td>2003</td>\n",
       "      <td>160000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2500</td>\n",
       "      <td>2003</td>\n",
       "      <td>190000</td>\n",
       "      <td>2</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5000</td>\n",
       "      <td>2001</td>\n",
       "      <td>62000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1800</td>\n",
       "      <td>1999</td>\n",
       "      <td>163000</td>\n",
       "      <td>2</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1300</td>\n",
       "      <td>1997</td>\n",
       "      <td>138000</td>\n",
       "      <td>4</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  year   miles  doors   type\n",
       "0   22000  2012   13000      2    car\n",
       "1   14000  2010   30000      2    car\n",
       "2   13000  2010   73500      4    car\n",
       "3    9500  2009   78000      4    car\n",
       "4    9000  2007   47000      4    car\n",
       "5    4000  2006  124000      2    car\n",
       "6    3000  2004  177000      4    car\n",
       "7    2000  2004  209000      4  truck\n",
       "8    3000  2003  138000      2    car\n",
       "9    1900  2003  160000      4    car\n",
       "10   2500  2003  190000      2  truck\n",
       "11   5000  2001   62000      4    car\n",
       "12   1800  1999  163000      2  truck\n",
       "13   1300  1997  138000      4    car"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['type'] = train.type.map({'car':0, 'truck':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = train.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[feature_cols]\n",
    "y = train.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "treereg = DecisionTreeRegressor(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treereg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.cross_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c551402f0edd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtreereg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy as np\n",
    "scores = cross_val_score(treereg, X, y, cv=3, scoring='mean_squared_error')\n",
    "np.mean(np.sqrt(-scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste de un árbol de regresión<br>\n",
    "Veamos si podemos reducir el RMSE sintonizando el parámetro max_depth. Una forma de buscar un valor óptimo sería probar diferentes valores, uno por uno:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try max_depth=1 \n",
    "treereg = DecisionTreeRegressor(max_depth=1, random_state=1) scores = cross_val_score(treereg, X, y, cv=3, scoring='mean_squared_error') np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range = range(1, 11)\n",
    "\n",
    "# create an empty list to store the average RMSE for each value of max_depth\n",
    "RMSE_scores = []\n",
    "\n",
    "# use cross-validation with each value of max_depth\n",
    "for depth in max_depth_range:\n",
    "    treereg = DecisionTreeRegressor(max_depth=depth, random_state=1)\n",
    "    MSE_scores = cross_val_score(treereg, X, y, cv=3, scoring='mean_squared_error')\n",
    "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))\n",
    "\n",
    "# print the results\n",
    "RMSE_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth=3 was best, so fit a tree using that parameter \n",
    "treereg = DecisionTreeRegressor(max_depth=3, random_state=1) treereg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature':feature_cols, 'importance':treereg.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creando el diagrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "with open(\"tree_vehicles.dot\", 'wb') as f:\n",
    "    f = export_graphviz(treereg, out_file=f, feature_names=feature_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Nodos internos:</b><br>\n",
    "\n",
    "\"muestras\" es el número de observaciones en ese nodo antes de la división<br>\n",
    "\"mse\" es el error cuadrático medio calculado comparando los valores reales de respuesta en ese nodo con el valor medio de respuesta en ese nodo.<br>\n",
    "primera línea es la condición usada para dividir ese nodo (ir a la izquierda si es verdadero, ir a la derecha si es falso)<br>\n",
    "\n",
    "<b>Hojas:</b>\n",
    "\n",
    "\"muestras\" es el número de observaciones en ese nodo<br>\n",
    "\"valor\" es el valor medio de la respuesta en ese nodo<br>\n",
    "\"mse\" es el error cuadrático medio calculado comparando los valores reales de respuesta en ese nodo con \"valor\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Probando el modelo con datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the test data \n",
    "test = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT5/master/data/vehicles_test.csv') \n",
    "# encode car as 0 and truck as 1 \n",
    "test['type'] = test.type.map({'car':0, 'truck':1}) \n",
    "# print the data \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X_test = test[feature_cols]\n",
    "y_test = test.price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = treereg.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [3000, 6000, 12000]\n",
    "y_pred = [3057, 3057, 16333]\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arboles de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los árboles de clasificación son muy similares a los árboles de regresión. He aquí una rápida comparación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|árboles de regresión|árboles de clasificación|\n",
    "      |---|---|\n",
    "      |predecir una respuesta continua|predecir una respuesta categórica|\n",
    "      |predecir usando la respuesta media de cada hoja |predecir usando la clase más común de cada hoja|\n",
    "      |las divisiones se eligen para minimizar MSE|las divisiones se eligen para minimizar el índice de Gini (discutido a continuación)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criterios de partición para árboles de clasificación<br>\n",
    "A continuación, se presentan opciones comunes para los criterios de partición:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tasa de error de clasificación: fracción de las observaciones de entrenamiento en una región que no pertenece a la clase más común\n",
    "- Índice de Gini: medida de la varianza total entre clases en una región\n",
    "- centropía cruzada: numéricamente similar al índice de Gini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de la división es aumentar la \"pureza del nodo\", y resulta que el índice de Gini y la cruzentropía son mejores medidas de pureza que la tasa de error de clasificación. El índice de Gini es más rápido de calcular que el de centrocross, por lo que generalmente es el preferido (y es usado por scikit-learn por defecto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos de cálculos del índice de Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digamos que estamos prediciendo la supervivencia en el Titanic. En un nodo en particular, hay 25 individuos, de los cuales 10 sobrevivieron y 15 murieron. Así es como calculamos el índice de Gini antes de hacer una división:<br>\n",
    "El valor máximo del índice Gini es de 0,5, y se produce cuando las clases están perfectamente equilibradas en un nodo. El valor mínimo del índice Gini es 0, y ocurre cuando sólo hay una clase representada en un nodo. Así, un nodo con un índice de Gini más bajo se dice que es más \"puro\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al decidir entre particiones, el algoritmo del árbol de decisión elige la partición que maximiza la pureza del nodo resultante. Supongamos que el género fue la división que se está considerando, y los nodos resultantes son los siguientes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hombres: 2 sobrevivieron, 13 murieron<br>\n",
    "Hembras: 8 sobrevivieron, 2 murieron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar esta división, calculamos el promedio ponderado de los índices de Gini de los nodos resultantes:<br>\n",
    "Por lo tanto, la disminución del índice de Gini (y el aumento de la pureza) a partir de la división en sexos es de 0,21. El algoritmo del árbol de decisión elegirá esta división si ninguna otra división resulta en una mayor ganancia en pureza.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de árbol de clasificación en scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('https://raw.githubusercontent.com/justmarkham/DAT5/master/data/titanic_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elijamos nuestra variable de respuesta y algunas características, y repasemos cómo manejar las características categóricas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobrevivió: Esta es nuestra variable de respuesta, y ya está codificada como 0=muerto y 1=sobrevivido.<br>\n",
    "Clase P: Estas son las categorías de clase de pasajeros (1=primera clase, 2=segunda clase, 3=tercera clase). Están ordenados lógicamente, así que los dejaremos como están. (Si el árbol se divide en esta característica, las divisiones ocurrirán en 1.5 o 2.5.)<br>\n",
    "Sexo: Esta es una categoría binaria, por lo que debemos codificarla como 0=hembra y 1=hombre. (Si el árbol se divide en esta característica, la división ocurrirá en 0.5.)<br>\n",
    "Edad: Esta es una característica numérica, pero necesitamos rellenar los valores que faltan.<br>\n",
    "Embarcado: Este es el puerto de donde salieron. Hay tres categorías desordenadas, así que debemos crear variables ficticias y dejar caer un nivel como de costumbre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode female as 0 and male as 1\n",
    "titanic['Sex'] = titanic.Sex.map({'female':0, 'male':1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the missing values for age with the mean age\n",
    "titanic.Age.fillna(titanic.Age.mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create three dummy variables, drop the first dummy variable, and store the two remaining columns as a DataFrame\n",
    "embarked_dummies = pd.get_dummies(titanic.Embarked, prefix='Embarked').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the two dummy variable columns onto the original DataFrame\n",
    "titanic = pd.concat([titanic, embarked_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the updated DataFrame\n",
    "titanic.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Pclass', 'Sex', 'Age', 'Embarked_Q', 'Embarked_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic[feature_cols]\n",
    "y = titanic.Survived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treeclf = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "treeclf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tree_titanic.dot\", 'wb') as f:\n",
    "    f = export_graphviz(treeclf, out_file=f, feature_names=feature_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He aquí algunas ventajas y desventajas de los árboles de decisión de los que aún no hemos hablado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pueden especificarse como una serie de reglas, y se piensa que se aproximan más a la toma de decisiones humanas que otros modelos.\n",
    "- o paramétrico (será mejor que los modelos lineales si la relación entre las características y la respuesta es altamente no lineal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desventajas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El rendimiento (generalmente) no es competitivo con los mejores métodos de aprendizaje supervisado\n",
    "- Puede fácilmente sobredimensionar los datos de entrenamiento (se requiere afinación)\n",
    "- Pequeñas variaciones en los datos pueden resultar en un árbol completamente diferente (alta varianza)\n",
    "- La división binaria recurrente toma decisiones \"localmente óptimas\" que pueden no resultar en un árbol globalmente óptimo.\n",
    "- No suele funcionar bien si las clases están muy desequilibradas\n",
    "- No tiende a funcionar bien con conjuntos de datos muy pequeños\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es de resaltar que existe variantes del algoritmo de árbol de decisión: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algoritmos por particionamiento: \n",
    "    \n",
    "- C4.5\n",
    "- CART\n",
    "- ID3\n",
    "- CHAID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmos por cobertura:\n",
    "- AQ\n",
    "- CN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
