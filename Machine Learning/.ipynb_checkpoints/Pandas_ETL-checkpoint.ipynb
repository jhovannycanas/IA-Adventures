{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "% matplotlib inline\n",
    "\n",
    "# We read a dataset with weather data from The Netherlands\n",
    "df = pd.read_csv('weather.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask for the shape of our dataset\n",
    "# This returns the number of rows and columns\n",
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask for a more elaborate description of our data\n",
    "# Including datatypes for each column, index type, memory usage\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head() gets the first 5 rows\n",
    "df.head()\n",
    "\n",
    "# Or you can specify how many lines you want:\n",
    "# df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# tail() gets the last 5 rows\n",
    "df.tail()\n",
    "\n",
    " for the temperature\n",
    "df['TEMP'].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe gives a statistical overview of our data\n",
    "df.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean() calculates the mean per column\n",
    "df.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max() calculates the maximum per column\n",
    "df.max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These types of functions can also be called on a single column\n",
    "# Here we calculate the minimum value in the pressure column\n",
    "df['PRESSURE'].min()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode() returns the most occurring value in the column\n",
    "df['TEMP'].mode()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a column is very easy\n",
    "df['TEMP'].plot()\n",
    "\n",
    "# There are several types of plot we can make\n",
    "# This example shows a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Describe gives a statistical overview of our data\n",
    "df.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean() calculates the mean per column\n",
    "df.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max() calculates the maximum per column\n",
    "df.max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These types of functions can also be called on a single column\n",
    "# Here we calculate the minimum value in the pressure column\n",
    "df['PRESSURE'].min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mode() returns the most occurring value in the column\n",
    "df['TEMP'].mode()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a column is very easy\n",
    "df['TEMP'].plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several types of plot we can make\n",
    "# This example shows a histogram for the temperature\n",
    "df['TEMP'].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting Missing Values\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('weather_m4.csv')\n",
    "df.info()\n",
    "\n",
    "df[['MIN_TEMP_GROUND', 'VIEW_RANGE', 'CLOUD', 'WEATHER_CODE']].head(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all columns with null values\n",
    "df.isnull().any()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all rows with null values\n",
    "df[df.isnull().any(axis=1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any rows with only null values?\n",
    "df.isnull().all(axis=1).any()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any columns with no null values at all?\n",
    "df.notnull().all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmm.. seems like this column only has a value every 6th row.. let's check this\n",
    "df['MIN_TEMP_GROUND']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series containing indices for every 6th row\n",
    "every_6th_row = pd.Series(range(5, len(df), 6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all these rows NOT null?\n",
    "df['MIN_TEMP_GROUND'][every_6th_row].notnull().all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all other rows null?\n",
    "# Q: Can you rewrite this line to use df.loc?\n",
    "df['MIN_TEMP_GROUND'].drop(every_6th_row).isnull().all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values\n",
    "\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop can be used to remove columns and/or rows\n",
    "df.drop(columns='WEATHER_CODE', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use fillna() to fill in missing data based on the data that is present\n",
    "df['MIN_TEMP_GROUND'].fillna(method='bfill', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have no more nulls in MIN_TEMP_GROUND\n",
    "# what are the dates where missing values occur?\n",
    "df.loc[df.isnull().any(axis=1), 'YYYYMMDD'].drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortest solution: Just drop everything\n",
    "nulls_dropped = df.dropna()\n",
    "nulls_dropped.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But note that our index is now discontinuous\n",
    "nulls_dropped[5300:5310]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another idea: just drop rows that have less than 7 columns filled\n",
    "# This leaves us with only two rows that contain null values\n",
    "drop_thresh = df.dropna(thresh=7)\n",
    "drop_thresh[drop_thresh.isnull().any(axis=1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or let's just look at the missing data again..\n",
    "rows_to_fill = df.isnull().any(axis=1)\n",
    "df[rows_to_fill]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We might fill all null values with the mean of the corresponding column\n",
    "nulls_filled = df.fillna(df.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the result\n",
    "nulls_filled[rows_to_fill]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or you could fill the null values with the mode\n",
    "df.fillna(df.mode().iloc[0], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Outliers\n",
    "\n",
    "athletes = pd.read_csv('athletes.csv')\n",
    "athletes.info()\n",
    "\n",
    "% matplotlib inline\n",
    "athletes.plot.scatter(x='height', y='weight')\n",
    "\n",
    "heights = athletes['height']\n",
    "heights.plot.box()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = heights.quantile(.25)\n",
    "q3 = heights.quantile(.75)\n",
    "iqr = q3 - q1 \n",
    "pmin = q1 - 1.5 * iqr\n",
    "pmax = q3 + 1.5 * iqr\n",
    "nwh = heights.where(heights.between(pmin, pmax))\n",
    "\n",
    "compare = pd.DataFrame({'before':heights, 'after':nwh})\n",
    "compare.plot.box()\n",
    "compare.describe()\n",
    "\n",
    "heights.where(heights.between(pmin, pmax), inplace=True)\n",
    "\n",
    "athletes.plot.scatter(x='height', y='weight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Duplicates\n",
    "\n",
    "athletes.duplicated().any()\n",
    "\n",
    "athletes[athletes.duplicated()]\n",
    "\n",
    "athletes.drop_duplicates(inplace=True)\n",
    "\n",
    "athletes['nationality'].drop_duplicates().sort_values()\n",
    "\n",
    "athletes['nationality'].value_counts()\n",
    "\n",
    "athletes['sex'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Types\n",
    "\n",
    "athletes.info()\n",
    "\n",
    "athletes[['gold', 'silver', 'bronze']].head()\n",
    "\n",
    "athletes[athletes['gold'] == 'O']\n",
    "\n",
    "athletes.loc[7521, ['gold', 'silver', 'bronze']] = 0\n",
    "\n",
    "athletes[['gold', 'silver', 'bronze']] = athletes[['gold', 'silver', 'bronze']].astype(int)\n",
    "\n",
    "athletes[['gold', 'silver', 'bronze']].sum()\n",
    "\n",
    "athletes.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Indexes\n",
    "\n",
    "athletes.head()\n",
    "\n",
    "athletes.set_index('id', drop=True, inplace=True)\n",
    "athletes.head()\n",
    "\n",
    "athletes.rename(\n",
    "    columns={\"nationality\": \"country\", \"sport\": \"discipline\"}, \n",
    "    inplace=True)\n",
    "athletes.head()\n",
    "\n",
    "df = pd.read_csv('weather_m4.csv')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.info()\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical Operations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(np.ones([5,4]), columns=['a', 'b', 'c', 'd'])\n",
    "df\n",
    "\n",
    "# Basic math operations on a DataFrame perform the computation for every cell\n",
    "df *= 2\n",
    "df\n",
    "\n",
    "# You can also do calculations on specific rows or columns\n",
    "df.loc[1] /= 2\n",
    "df['b'] -= 1\n",
    "df\n",
    "\n",
    "df2 = pd.DataFrame(np.ones([3,2]), columns=['d', 'e'], index=[2,4,5])\n",
    "df2\n",
    "\n",
    "# Operating on two DataFrames:\n",
    "# NaN for every combination of index/column that is not present in both inputs\n",
    "df + df2\n",
    "\n",
    "# The same is true for operations on two Series\n",
    "df.loc[2] * df2.loc[5]\n",
    "\n",
    "df.mean()\n",
    "\n",
    "# This is an operation on a DataFrame and a Series\n",
    "# Series indices are matched on DataFrame column labels\n",
    "df - df.mean()\n",
    "\n",
    "# Another operation on DataFrame and Series\n",
    "# Here, again, we see that we get NaN if labels are not present in both inputs\n",
    "df - pd.Series({'a':5, 'b':5, 'e':5, 'f': 5})\n",
    "\n",
    "# Normal math operators cannot get an axis argument\n",
    "# To do this, there are functions for every math operator\n",
    "df.sub( df.mean(axis=1), axis=0)\n",
    "\n",
    "# Function Application\n",
    "\n",
    "df = pd.DataFrame({'sin': np.arange(0, 5*np.pi, 0.01), \n",
    "                   'cos': np.arange(0.5*np.pi, 5.5*np.pi, 0.01)})\n",
    "\n",
    "# Numpy ufuncs like np.sin operate on every cell\n",
    "# Here we compute the sin for every cell in the dataframe\n",
    "df = np.sin(df)\n",
    "\n",
    "% matplotlib inline\n",
    "df.plot()\n",
    "\n",
    "def iqr(col):\n",
    "    q1 = col.quantile(.25)\n",
    "    q3 = col.quantile(.75)\n",
    "    return q3 - q1 \n",
    "\n",
    "# df.apply() executes the given function on a whole row or column\n",
    "df.apply(iqr)\n",
    "\n",
    "def somefunc(x):\n",
    "    return np.abs(x+.25)\n",
    "\n",
    "# df.applymap() applies the given function for every cell in the DataFrame\n",
    "df.applymap(somefunc).plot()\n",
    "\n",
    "## Groups and Aggregations with groupby()\n",
    "\n",
    "athletes = pd.read_csv('athletes.csv')\n",
    "athletes.info()\n",
    "\n",
    "# Simply calling groupby returns a GroupBy object \n",
    "# This does not calculate anything yet!\n",
    "g = athletes.groupby('nationality')[['gold', 'silver', 'bronze']]\n",
    "\n",
    "# Calling an aggregation function on the GroupBy object\n",
    "# applies the calculation for every group\n",
    "# and constructs a DataFrame with the results\n",
    "g.sum()\n",
    "\n",
    "# We can select multiple columns to group by\n",
    "# And we can select a subset of columns to do\n",
    "g = athletes.groupby(['sport', 'sex'])[['weight', 'height']]\n",
    "\n",
    "# Because we selected only 2 columns, this calculation will now be cheaper\n",
    "g.mean()\n",
    "\n",
    "# Reshaping Rows and Colums with stack() and unstack()\n",
    "\n",
    "m = pd.read_csv('monthly_data.csv')\n",
    "m\n",
    "\n",
    "# Preparation: move the 'YYYY' column into the index\n",
    "m.set_index('YYYY', inplace=True)\n",
    "m\n",
    "\n",
    "# stack() moves data from rows into a single column\n",
    "m.stack()\n",
    "\n",
    "# stack() also allows quick calculations over all cells\n",
    "m.stack().sum()\n",
    "\n",
    "w = athletes.groupby(['sport', 'sex'])['weight'].mean()\n",
    "w\n",
    "\n",
    "# unstack() takes the inner index level and creates a column for every unique index\n",
    "# It then moves the data into these columns\n",
    "w.unstack()\n",
    "\n",
    "# Reshaping Rows and Colums with pivot()\n",
    "\n",
    "p = pd.DataFrame({'id': [823905, 823905,\n",
    "                         235897, 235897, 235897,\n",
    "                         983422, 983422],\n",
    "                  'item': ['prize', 'unit', \n",
    "                           'prize', 'unit', 'stock', \n",
    "                           'prize', 'stock'],\n",
    "                  'value': [3.49, 'kg',\n",
    "                            12.89, 'l', 50,\n",
    "                            0.49, 4]})\n",
    "p\n",
    "\n",
    "# pivot() moves data from rows into columns\n",
    "# so that we end up with a wider, shorter DataFrame\n",
    "\n",
    "# The first argument is the column that will be used for row indices\n",
    "# The second argument is the column that will be used to create column labels\n",
    "p.pivot('id', 'item')\n",
    "\n",
    "grades = pd.DataFrame([[6, 4, 5], [7, 8, 7], [6, 7, 9], [6, 5, 5], [5, 2, 7]], \n",
    "                       index = ['Mary', 'John', 'Ann', 'Pete', 'Laura'],\n",
    "                       columns = ['test_1', 'test_2', 'test_3'])\n",
    "grades.reset_index(inplace=True)\n",
    "grades\n",
    "\n",
    "# melt() is the opposite of pivot()\n",
    "# It moves the data from the rows into a single column\n",
    "# The column names will show up in a new column called \"variable\"\n",
    "grades.melt(id_vars=['index'])\n",
    "\n",
    "# Combining Datasets\n",
    "\n",
    "grades = pd.DataFrame([[6, 4, 5], [7, 8, 7], [6, 7, 9], [6, 5, 5], [5, 2, 7]], \n",
    "                       index = ['Mary', 'John', 'Ann', 'Pete', 'Laura'],\n",
    "                       columns = ['test_1', 'test_2', 'test_3'])\n",
    "grades\n",
    "\n",
    "# Adding a new column -- needs an indexed datastructure (Series)\n",
    "grades['test_4'] = pd.Series({'John': 5, 'Ann': 8, 'Pete': 9, 'Mary': 7, 'Laura': 10})\n",
    "grades\n",
    "\n",
    "# Adding a row with .loc -- no Series necessary\n",
    "grades.loc['Bob'] = [2,3,4,5]\n",
    "grades\n",
    "\n",
    "# We can also use append\n",
    "# But in that case we need a Series with a name (will be used as row index)\n",
    "new_row = pd.Series({'test_1': 5, 'test_2': 6, 'test_3': 7, 'test_4': 8}, name=\"Kim\")\n",
    "grades.append(new_row)\n",
    "\n",
    "grades['stud_nr'] = [113, 121, 123, 135, 139, 141]\n",
    "grades = grades[['stud_nr', 'test_1', 'test_2', 'test_3', 'test_4']]\n",
    "grades\n",
    "\n",
    "other = pd.DataFrame([[139, 7, 7],\n",
    "                       [123, 8, 6],\n",
    "                       [142, 4, 5],\n",
    "                       [113, 7, 9],\n",
    "                       [155, 10, 9],\n",
    "                       [121, 6, 4]], \n",
    "                       columns = ['stud_nr', 'exam1', 'exam2'])\n",
    "other\n",
    "\n",
    "# Merging two DataFrames\n",
    "# By default this does an inner join on the common column (stud_nr)\n",
    "grades.merge(other)\n",
    "\n",
    "# We can also specify other join types: left, right, outer\n",
    "grades.merge(other, how='outer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
