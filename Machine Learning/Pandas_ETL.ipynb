{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# We read a dataset with weather data from The Netherlands\n",
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask for the shape of our dataset\n",
    "# This returns the number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Ask for a more elaborate description of our data\n",
    "# Including datatypes for each column, index type, memory usage\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head() gets the first 5 rows\n",
    "df.head()\n",
    "\n",
    "# Or you can specify how many lines you want:\n",
    "# df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20c74672940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tail() gets the last 5 rows\n",
    "df.tail()\n",
    "\n",
    "#for the temperature\n",
    "df['Age'].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe gives a statistical overview of our data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean() calculates the mean per column\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max() calculates the maximum per column\n",
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These types of functions can also be called on a single column\n",
    "# Here we calculate the minimum value in the pressure column\n",
    "df['PRESSURE'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode() returns the most occurring value in the column\n",
    "df['TEMP'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a column is very easy\n",
    "df['TEMP'].plot()\n",
    "\n",
    "# There are several types of plot we can make\n",
    "# This example shows a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe gives a statistical overview of our data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean() calculates the mean per column\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max() calculates the maximum per column\n",
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These types of functions can also be called on a single column\n",
    "# Here we calculate the minimum value in the pressure column\n",
    "df['PRESSURE'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode() returns the most occurring value in the column\n",
    "df['TEMP'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a column is very easy\n",
    "df['TEMP'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several types of plot we can make\n",
    "# This example shows a histogram for the temperature\n",
    "df['TEMP'].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting Missing Values\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('weather_m4.csv')\n",
    "df.info()\n",
    "\n",
    "df[['MIN_TEMP_GROUND', 'VIEW_RANGE', 'CLOUD', 'WEATHER_CODE']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all columns with null values\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all rows with null values\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any rows with only null values?\n",
    "df.isnull().all(axis=1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any columns with no null values at all?\n",
    "df.notnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmm.. seems like this column only has a value every 6th row.. let's check this\n",
    "df['MIN_TEMP_GROUND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series containing indices for every 6th row\n",
    "every_6th_row = pd.Series(range(5, len(df), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all these rows NOT null?\n",
    "df['MIN_TEMP_GROUND'][every_6th_row].notnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all other rows null?\n",
    "# Q: Can you rewrite this line to use df.loc?\n",
    "df['MIN_TEMP_GROUND'].drop(every_6th_row).isnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop can be used to remove columns and/or rows\n",
    "df.drop(columns='WEATHER_CODE', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use fillna() to fill in missing data based on the data that is present\n",
    "df['MIN_TEMP_GROUND'].fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have no more nulls in MIN_TEMP_GROUND\n",
    "# what are the dates where missing values occur?\n",
    "df.loc[df.isnull().any(axis=1), 'YYYYMMDD'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortest solution: Just drop everything\n",
    "nulls_dropped = df.dropna()\n",
    "nulls_dropped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But note that our index is now discontinuous\n",
    "nulls_dropped[5300:5310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another idea: just drop rows that have less than 7 columns filled\n",
    "# This leaves us with only two rows that contain null values\n",
    "drop_thresh = df.dropna(thresh=7)\n",
    "drop_thresh[drop_thresh.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or let's just look at the missing data again..\n",
    "rows_to_fill = df.isnull().any(axis=1)\n",
    "df[rows_to_fill]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We might fill all null values with the mean of the corresponding column\n",
    "nulls_filled = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the result\n",
    "nulls_filled[rows_to_fill]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or you could fill the null values with the mode\n",
    "df.fillna(df.mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Outliers\n",
    "\n",
    "athletes = pd.read_csv('athletes.csv')\n",
    "athletes.info()\n",
    "\n",
    "% matplotlib inline\n",
    "athletes.plot.scatter(x='height', y='weight')\n",
    "\n",
    "heights = athletes['height']\n",
    "heights.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = heights.quantile(.25)\n",
    "q3 = heights.quantile(.75)\n",
    "iqr = q3 - q1 \n",
    "pmin = q1 - 1.5 * iqr\n",
    "pmax = q3 + 1.5 * iqr\n",
    "nwh = heights.where(heights.between(pmin, pmax))\n",
    "\n",
    "compare = pd.DataFrame({'before':heights, 'after':nwh})\n",
    "compare.plot.box()\n",
    "compare.describe()\n",
    "\n",
    "heights.where(heights.between(pmin, pmax), inplace=True)\n",
    "\n",
    "athletes.plot.scatter(x='height', y='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Duplicates\n",
    "\n",
    "athletes.duplicated().any()\n",
    "\n",
    "athletes[athletes.duplicated()]\n",
    "\n",
    "athletes.drop_duplicates(inplace=True)\n",
    "\n",
    "athletes['nationality'].drop_duplicates().sort_values()\n",
    "\n",
    "athletes['nationality'].value_counts()\n",
    "\n",
    "athletes['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Types\n",
    "\n",
    "athletes.info()\n",
    "\n",
    "athletes[['gold', 'silver', 'bronze']].head()\n",
    "\n",
    "athletes[athletes['gold'] == 'O']\n",
    "\n",
    "athletes.loc[7521, ['gold', 'silver', 'bronze']] = 0\n",
    "\n",
    "athletes[['gold', 'silver', 'bronze']] = athletes[['gold', 'silver', 'bronze']].astype(int)\n",
    "\n",
    "athletes[['gold', 'silver', 'bronze']].sum()\n",
    "\n",
    "athletes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Indexes\n",
    "\n",
    "athletes.head()\n",
    "\n",
    "athletes.set_index('id', drop=True, inplace=True)\n",
    "athletes.head()\n",
    "\n",
    "athletes.rename(\n",
    "    columns={\"nationality\": \"country\", \"sport\": \"discipline\"}, \n",
    "    inplace=True)\n",
    "athletes.head()\n",
    "\n",
    "df = pd.read_csv('weather_m4.csv')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.info()\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical Operations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(np.ones([5,4]), columns=['a', 'b', 'c', 'd'])\n",
    "df\n",
    "\n",
    "# Basic math operations on a DataFrame perform the computation for every cell\n",
    "df *= 2\n",
    "df\n",
    "\n",
    "# You can also do calculations on specific rows or columns\n",
    "df.loc[1] /= 2\n",
    "df['b'] -= 1\n",
    "df\n",
    "\n",
    "df2 = pd.DataFrame(np.ones([3,2]), columns=['d', 'e'], index=[2,4,5])\n",
    "df2\n",
    "\n",
    "# Operating on two DataFrames:\n",
    "# NaN for every combination of index/column that is not present in both inputs\n",
    "df + df2\n",
    "\n",
    "# The same is true for operations on two Series\n",
    "df.loc[2] * df2.loc[5]\n",
    "\n",
    "df.mean()\n",
    "\n",
    "# This is an operation on a DataFrame and a Series\n",
    "# Series indices are matched on DataFrame column labels\n",
    "df - df.mean()\n",
    "\n",
    "# Another operation on DataFrame and Series\n",
    "# Here, again, we see that we get NaN if labels are not present in both inputs\n",
    "df - pd.Series({'a':5, 'b':5, 'e':5, 'f': 5})\n",
    "\n",
    "# Normal math operators cannot get an axis argument\n",
    "# To do this, there are functions for every math operator\n",
    "df.sub( df.mean(axis=1), axis=0)\n",
    "\n",
    "# Function Application\n",
    "\n",
    "df = pd.DataFrame({'sin': np.arange(0, 5*np.pi, 0.01), \n",
    "                   'cos': np.arange(0.5*np.pi, 5.5*np.pi, 0.01)})\n",
    "\n",
    "# Numpy ufuncs like np.sin operate on every cell\n",
    "# Here we compute the sin for every cell in the dataframe\n",
    "df = np.sin(df)\n",
    "\n",
    "% matplotlib inline\n",
    "df.plot()\n",
    "\n",
    "def iqr(col):\n",
    "    q1 = col.quantile(.25)\n",
    "    q3 = col.quantile(.75)\n",
    "    return q3 - q1 \n",
    "\n",
    "# df.apply() executes the given function on a whole row or column\n",
    "df.apply(iqr)\n",
    "\n",
    "def somefunc(x):\n",
    "    return np.abs(x+.25)\n",
    "\n",
    "# df.applymap() applies the given function for every cell in the DataFrame\n",
    "df.applymap(somefunc).plot()\n",
    "\n",
    "## Groups and Aggregations with groupby()\n",
    "\n",
    "athletes = pd.read_csv('athletes.csv')\n",
    "athletes.info()\n",
    "\n",
    "# Simply calling groupby returns a GroupBy object \n",
    "# This does not calculate anything yet!\n",
    "g = athletes.groupby('nationality')[['gold', 'silver', 'bronze']]\n",
    "\n",
    "# Calling an aggregation function on the GroupBy object\n",
    "# applies the calculation for every group\n",
    "# and constructs a DataFrame with the results\n",
    "g.sum()\n",
    "\n",
    "# We can select multiple columns to group by\n",
    "# And we can select a subset of columns to do\n",
    "g = athletes.groupby(['sport', 'sex'])[['weight', 'height']]\n",
    "\n",
    "# Because we selected only 2 columns, this calculation will now be cheaper\n",
    "g.mean()\n",
    "\n",
    "# Reshaping Rows and Colums with stack() and unstack()\n",
    "\n",
    "m = pd.read_csv('monthly_data.csv')\n",
    "m\n",
    "\n",
    "# Preparation: move the 'YYYY' column into the index\n",
    "m.set_index('YYYY', inplace=True)\n",
    "m\n",
    "\n",
    "# stack() moves data from rows into a single column\n",
    "m.stack()\n",
    "\n",
    "# stack() also allows quick calculations over all cells\n",
    "m.stack().sum()\n",
    "\n",
    "w = athletes.groupby(['sport', 'sex'])['weight'].mean()\n",
    "w\n",
    "\n",
    "# unstack() takes the inner index level and creates a column for every unique index\n",
    "# It then moves the data into these columns\n",
    "w.unstack()\n",
    "\n",
    "# Reshaping Rows and Colums with pivot()\n",
    "\n",
    "p = pd.DataFrame({'id': [823905, 823905,\n",
    "                         235897, 235897, 235897,\n",
    "                         983422, 983422],\n",
    "                  'item': ['prize', 'unit', \n",
    "                           'prize', 'unit', 'stock', \n",
    "                           'prize', 'stock'],\n",
    "                  'value': [3.49, 'kg',\n",
    "                            12.89, 'l', 50,\n",
    "                            0.49, 4]})\n",
    "p\n",
    "\n",
    "# pivot() moves data from rows into columns\n",
    "# so that we end up with a wider, shorter DataFrame\n",
    "\n",
    "# The first argument is the column that will be used for row indices\n",
    "# The second argument is the column that will be used to create column labels\n",
    "p.pivot('id', 'item')\n",
    "\n",
    "grades = pd.DataFrame([[6, 4, 5], [7, 8, 7], [6, 7, 9], [6, 5, 5], [5, 2, 7]], \n",
    "                       index = ['Mary', 'John', 'Ann', 'Pete', 'Laura'],\n",
    "                       columns = ['test_1', 'test_2', 'test_3'])\n",
    "grades.reset_index(inplace=True)\n",
    "grades\n",
    "\n",
    "# melt() is the opposite of pivot()\n",
    "# It moves the data from the rows into a single column\n",
    "# The column names will show up in a new column called \"variable\"\n",
    "grades.melt(id_vars=['index'])\n",
    "\n",
    "# Combining Datasets\n",
    "\n",
    "grades = pd.DataFrame([[6, 4, 5], [7, 8, 7], [6, 7, 9], [6, 5, 5], [5, 2, 7]], \n",
    "                       index = ['Mary', 'John', 'Ann', 'Pete', 'Laura'],\n",
    "                       columns = ['test_1', 'test_2', 'test_3'])\n",
    "grades\n",
    "\n",
    "# Adding a new column -- needs an indexed datastructure (Series)\n",
    "grades['test_4'] = pd.Series({'John': 5, 'Ann': 8, 'Pete': 9, 'Mary': 7, 'Laura': 10})\n",
    "grades\n",
    "\n",
    "# Adding a row with .loc -- no Series necessary\n",
    "grades.loc['Bob'] = [2,3,4,5]\n",
    "grades\n",
    "\n",
    "# We can also use append\n",
    "# But in that case we need a Series with a name (will be used as row index)\n",
    "new_row = pd.Series({'test_1': 5, 'test_2': 6, 'test_3': 7, 'test_4': 8}, name=\"Kim\")\n",
    "grades.append(new_row)\n",
    "\n",
    "grades['stud_nr'] = [113, 121, 123, 135, 139, 141]\n",
    "grades = grades[['stud_nr', 'test_1', 'test_2', 'test_3', 'test_4']]\n",
    "grades\n",
    "\n",
    "other = pd.DataFrame([[139, 7, 7],\n",
    "                       [123, 8, 6],\n",
    "                       [142, 4, 5],\n",
    "                       [113, 7, 9],\n",
    "                       [155, 10, 9],\n",
    "                       [121, 6, 4]], \n",
    "                       columns = ['stud_nr', 'exam1', 'exam2'])\n",
    "other\n",
    "\n",
    "# Merging two DataFrames\n",
    "# By default this does an inner join on the common column (stud_nr)\n",
    "grades.merge(other)\n",
    "\n",
    "# We can also specify other join types: left, right, outer\n",
    "grades.merge(other, how='outer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
