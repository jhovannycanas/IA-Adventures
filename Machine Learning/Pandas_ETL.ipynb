{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# We read a dataset with weather data from The Netherlands\n",
    "df = pd.read_csv('data/weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8784, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask for the shape of our dataset\n",
    "# This returns the number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8784 entries, 0 to 8783\n",
      "Data columns (total 5 columns):\n",
      "MONTH       8784 non-null int64\n",
      "DAY         8784 non-null int64\n",
      "TIME        8784 non-null int64\n",
      "TEMP        8784 non-null float64\n",
      "PRESSURE    8784 non-null int64\n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 343.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Ask for a more elaborate description of our data\n",
    "# Including datatypes for each column, index type, memory usage\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head() gets the first 5 rows\n",
    "df.head()\n",
    "\n",
    "# Or you can specify how many lines you want:\n",
    "# df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dd526a7978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tail() gets the last 5 rows\n",
    "df.tail()\n",
    "\n",
    "#for the temperature\n",
    "df['PRESSURE'].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe gives a statistical overview of our data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean() calculates the mean per column\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max() calculates the maximum per column\n",
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These types of functions can also be called on a single column\n",
    "# Here we calculate the minimum value in the pressure column\n",
    "df['PRESSURE'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode() returns the most occurring value in the column\n",
    "df['TEMP'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a column is very easy\n",
    "df['TEMP'].plot()\n",
    "\n",
    "# There are several types of plot we can make\n",
    "# This example shows a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe gives a statistical overview of our data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean() calculates the mean per column\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max() calculates the maximum per column\n",
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These types of functions can also be called on a single column\n",
    "# Here we calculate the minimum value in the pressure column\n",
    "df['PRESSURE'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode() returns the most occurring value in the column\n",
    "df['TEMP'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a column is very easy\n",
    "df['TEMP'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several types of plot we can make\n",
    "# This example shows a histogram for the temperature\n",
    "df['TEMP'].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting Missing Values\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('weather_m4.csv')\n",
    "df.info()\n",
    "\n",
    "df[['MIN_TEMP_GROUND', 'VIEW_RANGE', 'CLOUD', 'WEATHER_CODE']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all columns with null values\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all rows with null values\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any rows with only null values?\n",
    "df.isnull().all(axis=1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any columns with no null values at all?\n",
    "df.notnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmm.. seems like this column only has a value every 6th row.. let's check this\n",
    "df['MIN_TEMP_GROUND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series containing indices for every 6th row\n",
    "every_6th_row = pd.Series(range(5, len(df), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all these rows NOT null?\n",
    "df['MIN_TEMP_GROUND'][every_6th_row].notnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are all other rows null?\n",
    "# Q: Can you rewrite this line to use df.loc?\n",
    "df['MIN_TEMP_GROUND'].drop(every_6th_row).isnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop can be used to remove columns and/or rows\n",
    "df.drop(columns='WEATHER_CODE', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use fillna() to fill in missing data based on the data that is present\n",
    "df['MIN_TEMP_GROUND'].fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have no more nulls in MIN_TEMP_GROUND\n",
    "# what are the dates where missing values occur?\n",
    "df.loc[df.isnull().any(axis=1), 'YYYYMMDD'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortest solution: Just drop everything\n",
    "nulls_dropped = df.dropna()\n",
    "nulls_dropped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But note that our index is now discontinuous\n",
    "nulls_dropped[5300:5310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another idea: just drop rows that have less than 7 columns filled\n",
    "# This leaves us with only two rows that contain null values\n",
    "drop_thresh = df.dropna(thresh=7)\n",
    "drop_thresh[drop_thresh.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or let's just look at the missing data again..\n",
    "rows_to_fill = df.isnull().any(axis=1)\n",
    "df[rows_to_fill]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We might fill all null values with the mean of the corresponding column\n",
    "nulls_filled = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the result\n",
    "nulls_filled[rows_to_fill]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or you could fill the null values with the mode\n",
    "df.fillna(df.mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Outliers\n",
    "\n",
    "athletes = pd.read_csv('athletes.csv')\n",
    "athletes.info()\n",
    "\n",
    "% matplotlib inline\n",
    "athletes.plot.scatter(x='height', y='weight')\n",
    "\n",
    "heights = athletes['height']\n",
    "heights.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = heights.quantile(.25)\n",
    "q3 = heights.quantile(.75)\n",
    "iqr = q3 - q1 \n",
    "pmin = q1 - 1.5 * iqr\n",
    "pmax = q3 + 1.5 * iqr\n",
    "nwh = heights.where(heights.between(pmin, pmax))\n",
    "\n",
    "compare = pd.DataFrame({'before':heights, 'after':nwh})\n",
    "compare.plot.box()\n",
    "compare.describe()\n",
    "\n",
    "heights.where(heights.between(pmin, pmax), inplace=True)\n",
    "\n",
    "athletes.plot.scatter(x='height', y='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Duplicates\n",
    "\n",
    "athletes.duplicated().any()\n",
    "\n",
    "athletes[athletes.duplicated()]\n",
    "\n",
    "athletes.drop_duplicates(inplace=True)\n",
    "\n",
    "athletes['nationality'].drop_duplicates().sort_values()\n",
    "\n",
    "athletes['nationality'].value_counts()\n",
    "\n",
    "athletes['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Types\n",
    "\n",
    "athletes.info()\n",
    "\n",
    "athletes[['gold', 'silver', 'bronze']].head()\n",
    "\n",
    "athletes[athletes['gold'] == 'O']\n",
    "\n",
    "athletes.loc[7521, ['gold', 'silver', 'bronze']] = 0\n",
    "\n",
    "athletes[['gold', 'silver', 'bronze']] = athletes[['gold', 'silver', 'bronze']].astype(int)\n",
    "\n",
    "athletes[['gold', 'silver', 'bronze']].sum()\n",
    "\n",
    "athletes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Indexes\n",
    "\n",
    "athletes.head()\n",
    "\n",
    "athletes.set_index('id', drop=True, inplace=True)\n",
    "athletes.head()\n",
    "\n",
    "athletes.rename(\n",
    "    columns={\"nationality\": \"country\", \"sport\": \"discipline\"}, \n",
    "    inplace=True)\n",
    "athletes.head()\n",
    "\n",
    "df = pd.read_csv('weather_m4.csv')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.info()\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical Operations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(np.ones([5,4]), columns=['a', 'b', 'c', 'd'])\n",
    "df\n",
    "\n",
    "# Basic math operations on a DataFrame perform the computation for every cell\n",
    "df *= 2\n",
    "df\n",
    "\n",
    "# You can also do calculations on specific rows or columns\n",
    "df.loc[1] /= 2\n",
    "df['b'] -= 1\n",
    "df\n",
    "\n",
    "df2 = pd.DataFrame(np.ones([3,2]), columns=['d', 'e'], index=[2,4,5])\n",
    "df2\n",
    "\n",
    "# Operating on two DataFrames:\n",
    "# NaN for every combination of index/column that is not present in both inputs\n",
    "df + df2\n",
    "\n",
    "# The same is true for operations on two Series\n",
    "df.loc[2] * df2.loc[5]\n",
    "\n",
    "df.mean()\n",
    "\n",
    "# This is an operation on a DataFrame and a Series\n",
    "# Series indices are matched on DataFrame column labels\n",
    "df - df.mean()\n",
    "\n",
    "# Another operation on DataFrame and Series\n",
    "# Here, again, we see that we get NaN if labels are not present in both inputs\n",
    "df - pd.Series({'a':5, 'b':5, 'e':5, 'f': 5})\n",
    "\n",
    "# Normal math operators cannot get an axis argument\n",
    "# To do this, there are functions for every math operator\n",
    "df.sub( df.mean(axis=1), axis=0)\n",
    "\n",
    "# Function Application\n",
    "\n",
    "df = pd.DataFrame({'sin': np.arange(0, 5*np.pi, 0.01), \n",
    "                   'cos': np.arange(0.5*np.pi, 5.5*np.pi, 0.01)})\n",
    "\n",
    "# Numpy ufuncs like np.sin operate on every cell\n",
    "# Here we compute the sin for every cell in the dataframe\n",
    "df = np.sin(df)\n",
    "\n",
    "% matplotlib inline\n",
    "df.plot()\n",
    "\n",
    "def iqr(col):\n",
    "    q1 = col.quantile(.25)\n",
    "    q3 = col.quantile(.75)\n",
    "    return q3 - q1 \n",
    "\n",
    "# df.apply() executes the given function on a whole row or column\n",
    "df.apply(iqr)\n",
    "\n",
    "def somefunc(x):\n",
    "    return np.abs(x+.25)\n",
    "\n",
    "# df.applymap() applies the given function for every cell in the DataFrame\n",
    "df.applymap(somefunc).plot()\n",
    "\n",
    "## Groups and Aggregations with groupby()\n",
    "\n",
    "athletes = pd.read_csv('athletes.csv')\n",
    "athletes.info()\n",
    "\n",
    "# Simply calling groupby returns a GroupBy object \n",
    "# This does not calculate anything yet!\n",
    "g = athletes.groupby('nationality')[['gold', 'silver', 'bronze']]\n",
    "\n",
    "# Calling an aggregation function on the GroupBy object\n",
    "# applies the calculation for every group\n",
    "# and constructs a DataFrame with the results\n",
    "g.sum()\n",
    "\n",
    "# We can select multiple columns to group by\n",
    "# And we can select a subset of columns to do\n",
    "g = athletes.groupby(['sport', 'sex'])[['weight', 'height']]\n",
    "\n",
    "# Because we selected only 2 columns, this calculation will now be cheaper\n",
    "g.mean()\n",
    "\n",
    "# Reshaping Rows and Colums with stack() and unstack()\n",
    "\n",
    "m = pd.read_csv('monthly_data.csv')\n",
    "m\n",
    "\n",
    "# Preparation: move the 'YYYY' column into the index\n",
    "m.set_index('YYYY', inplace=True)\n",
    "m\n",
    "\n",
    "# stack() moves data from rows into a single column\n",
    "m.stack()\n",
    "\n",
    "# stack() also allows quick calculations over all cells\n",
    "m.stack().sum()\n",
    "\n",
    "w = athletes.groupby(['sport', 'sex'])['weight'].mean()\n",
    "w\n",
    "\n",
    "# unstack() takes the inner index level and creates a column for every unique index\n",
    "# It then moves the data into these columns\n",
    "w.unstack()\n",
    "\n",
    "# Reshaping Rows and Colums with pivot()\n",
    "\n",
    "p = pd.DataFrame({'id': [823905, 823905,\n",
    "                         235897, 235897, 235897,\n",
    "                         983422, 983422],\n",
    "                  'item': ['prize', 'unit', \n",
    "                           'prize', 'unit', 'stock', \n",
    "                           'prize', 'stock'],\n",
    "                  'value': [3.49, 'kg',\n",
    "                            12.89, 'l', 50,\n",
    "                            0.49, 4]})\n",
    "p\n",
    "\n",
    "# pivot() moves data from rows into columns\n",
    "# so that we end up with a wider, shorter DataFrame\n",
    "\n",
    "# The first argument is the column that will be used for row indices\n",
    "# The second argument is the column that will be used to create column labels\n",
    "p.pivot('id', 'item')\n",
    "\n",
    "grades = pd.DataFrame([[6, 4, 5], [7, 8, 7], [6, 7, 9], [6, 5, 5], [5, 2, 7]], \n",
    "                       index = ['Mary', 'John', 'Ann', 'Pete', 'Laura'],\n",
    "                       columns = ['test_1', 'test_2', 'test_3'])\n",
    "grades.reset_index(inplace=True)\n",
    "grades\n",
    "\n",
    "# melt() is the opposite of pivot()\n",
    "# It moves the data from the rows into a single column\n",
    "# The column names will show up in a new column called \"variable\"\n",
    "grades.melt(id_vars=['index'])\n",
    "\n",
    "# Combining Datasets\n",
    "\n",
    "grades = pd.DataFrame([[6, 4, 5], [7, 8, 7], [6, 7, 9], [6, 5, 5], [5, 2, 7]], \n",
    "                       index = ['Mary', 'John', 'Ann', 'Pete', 'Laura'],\n",
    "                       columns = ['test_1', 'test_2', 'test_3'])\n",
    "grades\n",
    "\n",
    "# Adding a new column -- needs an indexed datastructure (Series)\n",
    "grades['test_4'] = pd.Series({'John': 5, 'Ann': 8, 'Pete': 9, 'Mary': 7, 'Laura': 10})\n",
    "grades\n",
    "\n",
    "# Adding a row with .loc -- no Series necessary\n",
    "grades.loc['Bob'] = [2,3,4,5]\n",
    "grades\n",
    "\n",
    "# We can also use append\n",
    "# But in that case we need a Series with a name (will be used as row index)\n",
    "new_row = pd.Series({'test_1': 5, 'test_2': 6, 'test_3': 7, 'test_4': 8}, name=\"Kim\")\n",
    "grades.append(new_row)\n",
    "\n",
    "grades['stud_nr'] = [113, 121, 123, 135, 139, 141]\n",
    "grades = grades[['stud_nr', 'test_1', 'test_2', 'test_3', 'test_4']]\n",
    "grades\n",
    "\n",
    "other = pd.DataFrame([[139, 7, 7],\n",
    "                       [123, 8, 6],\n",
    "                       [142, 4, 5],\n",
    "                       [113, 7, 9],\n",
    "                       [155, 10, 9],\n",
    "                       [121, 6, 4]], \n",
    "                       columns = ['stud_nr', 'exam1', 'exam2'])\n",
    "other\n",
    "\n",
    "# Merging two DataFrames\n",
    "# By default this does an inner join on the common column (stud_nr)\n",
    "grades.merge(other)\n",
    "\n",
    "# We can also specify other join types: left, right, outer\n",
    "grades.merge(other, how='outer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
