{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = open(\"data/alice_in_wonderland.txt\", 'rb')\n",
    "lines = []\n",
    "for line in fin:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\", \"ignore\")\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "fin.close()\n",
    "text = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s': 0, '(': 1, '1': 2, ';': 3, '8': 4, '*': 5, '!': 6, ']': 7, 'r': 8, 'c': 9, 'd': 10, '#': 11, 't': 12, 'j': 13, 'q': 14, '@': 15, 'b': 16, 'l': 17, 'h': 18, '_': 19, '.': 20, ':': 21, '3': 22, '7': 23, 'e': 24, 'p': 25, '$': 26, 'a': 27, 'g': 28, '[': 29, '2': 30, 'n': 31, 'f': 32, '/': 33, '%': 34, 'x': 35, ',': 36, 'y': 37, 'm': 38, 'u': 39, '4': 40, '6': 41, '-': 42, '5': 43, 'o': 44, '?': 45, '0': 46, 'z': 47, ')': 48, 'k': 49, '9': 50, 'i': 51, ' ': 52, 'v': 53, 'w': 54}\n"
     ]
    }
   ],
   "source": [
    "print(char2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQLEN = 10\n",
    "STEP = 1\n",
    "input_chars = []\n",
    "label_chars = []\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i:i + SEQLEN])    \n",
    "    label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):    \n",
    "    for j, ch in enumerate(input_char):\n",
    "            X[i, j, char2index[ch]] = 1    \n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\jhovanny\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n",
    "    input_shape=(SEQLEN, nb_chars),\n",
    "    unroll=True))\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "WARNING:tensorflow:From c:\\users\\jhovanny\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 46us/step - loss: 2.3371\n",
      "Generating from seed: ms of this\n",
      "ms of this the wast of and the wast of and the wast of and the wast of and the wast of and the wast of and the==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 44us/step - loss: 2.0472\n",
      "Generating from seed: roject gut\n",
      "roject gutenberg the sald the sald the sald the sald the sald the sald the sald the sald the sald the sald the==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 44us/step - loss: 1.9404\n",
      "Generating from seed: s eat eggs\n",
      "s eat eggsent wish are the mare the mare the mare the mare the mare the mare the mare the mare the mare the ma==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 46us/step - loss: 1.8582\n",
      "Generating from seed: found hers\n",
      "found herself the of the courd the with a could the could the could the could the could the could the could th==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 8s 49us/step - loss: 1.7923\n",
      "Generating from seed:  me he was\n",
      " me he was a maid the was a come the rame the rame the rame the rame the rame the rame the rame the rame the r==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 47us/step - loss: 1.7406\n",
      "Generating from seed: th the irs\n",
      "th the irse the was a lattle sien a dong to be the was a lattle sien a dong to be the was a lattle sien a dong==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 41us/step - loss: 1.6955\n",
      "Generating from seed: ion he bit\n",
      "ion he bitt a ding at the courd at the rabbit was so the great dore the courd at the rabbit was so the great d==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 41us/step - loss: 1.6579\n",
      "Generating from seed: ars for ha\n",
      "ars for have could so the project gutenberg-tm ered to the project gutenberg-tm ered to the project gutenberg-==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 44us/step - loss: 1.6250\n",
      "Generating from seed: ? ive hear\n",
      "? ive hear so thing of the pook and down a this agreement to the project gutenberg-tm ered to the project gute==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 8s 51us/step - loss: 1.5967\n",
      "Generating from seed: me wine, t\n",
      "me wine, the march her hear the could the courd the could the courd the could the courd the could the courd th==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 8s 52us/step - loss: 1.5717\n",
      "Generating from seed: hedgehog h\n",
      "hedgehog her the hatter with and the mock turtle sook alice was a long the mock turtle sook alice was a long t==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 8s 50us/step - loss: 1.5497\n",
      "Generating from seed: gal fees. \n",
      "gal fees. the mouse the mock turtle so she said the mock turtle so she said the mock turtle so she said the mo==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 42us/step - loss: 1.5300\n",
      "Generating from seed:  state app\n",
      " state appeared. alice was the little got a garden the king said to herself the king said to herself the king ==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 8s 49us/step - loss: 1.5131\n",
      "Generating from seed:  a barrowf\n",
      " a barrowf on the this again, and the say on the sook on the sent on the toormed to herself the mock turtle se==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 8s 50us/step - loss: 1.4971\n",
      "Generating from seed: ppens. wha\n",
      "ppens. what alice and she was so much a form they was so mock turtle said the king and they was so mock turtle==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 8s 49us/step - loss: 1.4835\n",
      "Generating from seed: s, or ill \n",
      "s, or ill the white rabbit was some the project gutenberg thing its a long as it was a little good was a littl==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 8s 49us/step - loss: 1.4709\n",
      "Generating from seed: help produ\n",
      "help produce, said the mock turtle said to herself the mouse the mouse the mouse the mouse the mouse the mouse==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 8s 49us/step - loss: 1.4603\n",
      "Generating from seed: or pulling\n",
      "or pulling and she was she was she was she was she was she was she was she was she was she was she was she was==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 46us/step - loss: 1.4488\n",
      "Generating from seed: nberg-tm e\n",
      "nberg-tm electronic works in a sort of the some to do she was beanded the project gutenberg-tm electronic work==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 8s 47us/step - loss: 1.4404\n",
      "Generating from seed: song? oh, \n",
      "song? oh, as she said to the sable the toom a ground to the cook to the project gutenberg-tm electronic work o==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 45us/step - loss: 1.4311\n",
      "Generating from seed: leep insta\n",
      "leep instant the gryphon it was go and dont she had not get how it was the gryphon it was go and dont she had ==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 41us/step - loss: 1.4229\n",
      "Generating from seed: ecessarily\n",
      "ecessarily about her hear her little of the whole the whole the whole the whole the whole the whole the whole ==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 42us/step - loss: 1.4148\n",
      "Generating from seed: individual\n",
      "individual soon as it was go and ever at all the project gutenberg-tm electronic work is a minute or the the s==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 44us/step - loss: 1.4077\n",
      "Generating from seed: me order, \n",
      "me order, and the mouse had a large with the mouse had a large with the mouse had a large with the mouse had a==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 44us/step - loss: 1.4016\n",
      "Generating from seed: threw them\n",
      "threw them and said to the caterpillar was and said to the caterpillar was and said to the caterpillar was and\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    print(\"Generating from seed: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for i, ch in enumerate(test_chars):\n",
    "            Xtest[0, i, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2char[np.argmax(pred)]\n",
    "        print(ypred, end=\"\")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_chars = test_chars[1:] + ypred\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
