{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo vamos a implementar una CNN que permita clasificacion multiclase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso es crear 2 carpetas que son: la carpeta de entrenamiento y la carpeta de pruebas; luego dentro de cada una de ellas se deben ubicar N carpetas que denotan cada una de las clases, y dentro de cada una de estas carpetas deben  contener las respectivas imagenes correspondientes a la clase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![folder_data](img/folder_data.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras tiene una clase llamada ImageDataGenerator que permite hacer aumentos en tiempo real de las imagenes.En este ejmplo vamos a utilizar el metodo flow_from_directory()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es muy importante resaltar que el metodo flow_from_directory() espera una estructura similar a la que se presentan en la figura anterior para su correcto funcionamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los nombres de las carpetas para las clases son importantes, nombrarlas (o renombrarlas) con los nombres de las etiquetas respectivas para que sea más fácil para usted más tarde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso es crear una instancia de la clase ImageDataGenerator con algunas configuraciones basicas, como rotacion de 40 grados de la imagen, normalizacion de la imagen, acercamiento aleatorio de la imagen entre otros opciones disponibles para su consulta en el siguiente enlace:https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 3000\n",
    "nb_validation_samples = 320\n",
    "epochs = 50\n",
    "batch_size = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTRENAMIENTO_DIR = 'data/data/entrenamiento/'\n",
    "TEST_DIR = 'data/data/pruebas/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion se presenta la siguiente instruccion con los parametros comunmente utilizados para flow_from_directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2002 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=ENTRENAMIENTO_DIR,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- directory: ruta donde se encuentran las imagenes.\n",
    "- target_size: las imagenes de entrada sera redimenzionadas al tamaño que determine.\n",
    "- color_mode: si la imagen es en escala de grises colocar \"grayscale\", si es a color \"rgb\"\n",
    "- batch_size: numero de imagenes que se procesaran por el generador de lotes.\n",
    "- class_mode: si es un problema binario configure \"binary\", si es multi clases configure \"categorical\"\n",
    "- shuffle: configure True, si desea barajar las imagenes, de lo contrario configure False.\n",
    "- seed: Semilla aleatoria para aplicar un aumento de imagen aleatorio y barajar el orden de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igual paso para las imagenes de pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso anterior se configuro class_mode como None, porque solo requerimos que nos retorne las imagenes. En el caso de shuffle establezca esta opción en False, ya que necesita producir las imágenes en \"orden\", para predecir las salidas y hacerlas coincidir con sus ids o nombres de archivo únicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\jhovanny\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\jhovanny\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\jhovanny\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 65s 520ms/step - loss: 0.7058 - acc: 0.5235 - val_loss: 0.6732 - val_acc: 0.6025\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 62s 496ms/step - loss: 0.6660 - acc: 0.6015 - val_loss: 0.6538 - val_acc: 0.6175\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 63s 501ms/step - loss: 0.6342 - acc: 0.6645 - val_loss: 0.5978 - val_acc: 0.6700\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 64s 509ms/step - loss: 0.6167 - acc: 0.6700 - val_loss: 0.6184 - val_acc: 0.6625\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 65s 523ms/step - loss: 0.5853 - acc: 0.7125 - val_loss: 0.5588 - val_acc: 0.7275\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 68s 541ms/step - loss: 0.5637 - acc: 0.7095 - val_loss: 0.5925 - val_acc: 0.7175\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 67s 533ms/step - loss: 0.5608 - acc: 0.7225 - val_loss: 0.5965 - val_acc: 0.6825\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 61s 491ms/step - loss: 0.5361 - acc: 0.7405 - val_loss: 0.6054 - val_acc: 0.6975\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 63s 503ms/step - loss: 0.5215 - acc: 0.7545 - val_loss: 0.5476 - val_acc: 0.7300\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 64s 514ms/step - loss: 0.5133 - acc: 0.7545 - val_loss: 0.5503 - val_acc: 0.7375\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 63s 501ms/step - loss: 0.5084 - acc: 0.7705 - val_loss: 0.5301 - val_acc: 0.7600\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 62s 494ms/step - loss: 0.4870 - acc: 0.7765 - val_loss: 0.5726 - val_acc: 0.7475\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 67s 533ms/step - loss: 0.4884 - acc: 0.7635 - val_loss: 0.5459 - val_acc: 0.7500\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 68s 542ms/step - loss: 0.4666 - acc: 0.7900 - val_loss: 0.5950 - val_acc: 0.7275\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 68s 547ms/step - loss: 0.4510 - acc: 0.7915 - val_loss: 0.5804 - val_acc: 0.7150\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 63s 506ms/step - loss: 0.4463 - acc: 0.8030 - val_loss: 0.6884 - val_acc: 0.7000\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 69s 549ms/step - loss: 0.4358 - acc: 0.8095 - val_loss: 0.5257 - val_acc: 0.7575\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 69s 548ms/step - loss: 0.4609 - acc: 0.7865 - val_loss: 0.6183 - val_acc: 0.7250\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 67s 534ms/step - loss: 0.4368 - acc: 0.8025 - val_loss: 0.5339 - val_acc: 0.7225\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 65s 521ms/step - loss: 0.4267 - acc: 0.8105 - val_loss: 0.5143 - val_acc: 0.7450\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 71s 571ms/step - loss: 0.4329 - acc: 0.8070 - val_loss: 0.5743 - val_acc: 0.7325\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 69s 549ms/step - loss: 0.4359 - acc: 0.7950 - val_loss: 0.6130 - val_acc: 0.7175\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 63s 506ms/step - loss: 0.4169 - acc: 0.8180 - val_loss: 0.7518 - val_acc: 0.7000\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 65s 517ms/step - loss: 0.3997 - acc: 0.8190 - val_loss: 0.5785 - val_acc: 0.7600\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 64s 511ms/step - loss: 0.4195 - acc: 0.8085 - val_loss: 0.9428 - val_acc: 0.7025\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 64s 510ms/step - loss: 0.4153 - acc: 0.8155 - val_loss: 0.4841 - val_acc: 0.7525\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 63s 508ms/step - loss: 0.4672 - acc: 0.8095 - val_loss: 0.5447 - val_acc: 0.7400\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 65s 522ms/step - loss: 0.4116 - acc: 0.8205 - val_loss: 0.5093 - val_acc: 0.7500\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 70s 557ms/step - loss: 0.4421 - acc: 0.8125 - val_loss: 0.5542 - val_acc: 0.7275\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 64s 511ms/step - loss: 0.4267 - acc: 0.8105 - val_loss: 0.5479 - val_acc: 0.7750\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 72s 572ms/step - loss: 0.4114 - acc: 0.8255 - val_loss: 0.5184 - val_acc: 0.7575\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 72s 579ms/step - loss: 0.3907 - acc: 0.8315 - val_loss: 0.5644 - val_acc: 0.7350\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 67s 537ms/step - loss: 0.4076 - acc: 0.8255 - val_loss: 0.6356 - val_acc: 0.7575\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 62s 497ms/step - loss: 0.4040 - acc: 0.8325 - val_loss: 0.4958 - val_acc: 0.7800\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 62s 498ms/step - loss: 0.4179 - acc: 0.8325 - val_loss: 0.4961 - val_acc: 0.7750\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 71s 571ms/step - loss: 0.3833 - acc: 0.8375 - val_loss: 0.5495 - val_acc: 0.7575\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 70s 557ms/step - loss: 0.3992 - acc: 0.8350 - val_loss: 0.4785 - val_acc: 0.7725\n",
      "Epoch 38/50\n",
      " 52/125 [===========>..................] - ETA: 36s - loss: 0.4403 - acc: 0.8053"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo entrenaremos la CNN para clasificacion multiclase, para lo cual utilizaremos el siguiente dataset disponible en Kaggle: https://www.kaggle.com/jutrera/stanford-car-dataset-by-classes-folder/downloads/stanford-car-dataset-by-classes-folder.zip/2.<br>\n",
    "Las modificaciones que debemos realizar es configurar la perdidad como categorical_crossentropy y el parametro class_mode del metodo flow_from_directory en categorical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer paso definimos las rutas de la carpeta donde se encuentran ubicadas las imagenes, es importante respetar la estructura de carpetas para que el metodo flow_from_directory puede funcionar correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTRENAMIENTO_DIR = 'data/flowers/train/'\n",
    "TEST_DIR = 'data/flowers/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3523 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=ENTRENAMIENTO_DIR,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 34, 34, 96)        55392     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 34, 34, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 17, 17, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 15, 15, 128)       110720    \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 2565      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 3,399,845\n",
      "Trainable params: 3,399,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(96, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 174s 22s/step - loss: 1.5649 - acc: 0.2778 - val_loss: 1.4159 - val_acc: 0.3850\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 157s 20s/step - loss: 1.4179 - acc: 0.3608 - val_loss: 1.3193 - val_acc: 0.4675\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 137s 17s/step - loss: 1.2542 - acc: 0.4889 - val_loss: 1.1315 - val_acc: 0.5350\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 140s 17s/step - loss: 1.1130 - acc: 0.5438 - val_loss: 1.1721 - val_acc: 0.5375\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 145s 18s/step - loss: 1.0590 - acc: 0.5705 - val_loss: 1.0137 - val_acc: 0.6062\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 127s 16s/step - loss: 1.0120 - acc: 0.5887 - val_loss: 0.9844 - val_acc: 0.5925\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 153s 19s/step - loss: 0.9589 - acc: 0.6314 - val_loss: 0.9513 - val_acc: 0.6487\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 143s 18s/step - loss: 0.8867 - acc: 0.6535 - val_loss: 0.9421 - val_acc: 0.6437\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 143s 18s/step - loss: 0.8731 - acc: 0.6628 - val_loss: 0.9790 - val_acc: 0.6150\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 145s 18s/step - loss: 0.8412 - acc: 0.6616 - val_loss: 0.8845 - val_acc: 0.6900\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 142s 18s/step - loss: 0.8409 - acc: 0.6757 - val_loss: 0.9992 - val_acc: 0.6150\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 141s 18s/step - loss: 0.8218 - acc: 0.6830 - val_loss: 0.8561 - val_acc: 0.6725\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 130s 16s/step - loss: 0.7864 - acc: 0.7097 - val_loss: 0.7772 - val_acc: 0.7212\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 126s 16s/step - loss: 0.7487 - acc: 0.7190 - val_loss: 0.8388 - val_acc: 0.7088\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 125s 16s/step - loss: 0.7097 - acc: 0.7304 - val_loss: 0.7472 - val_acc: 0.7288\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 123s 15s/step - loss: 0.7134 - acc: 0.7145 - val_loss: 0.8368 - val_acc: 0.7100\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 118s 15s/step - loss: 0.7156 - acc: 0.7296 - val_loss: 0.8917 - val_acc: 0.6863\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 118s 15s/step - loss: 0.7251 - acc: 0.7211 - val_loss: 0.8235 - val_acc: 0.7087\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 123s 15s/step - loss: 0.6548 - acc: 0.7481 - val_loss: 0.8100 - val_acc: 0.7175\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 105s 13s/step - loss: 0.6074 - acc: 0.7716 - val_loss: 0.7138 - val_acc: 0.7288\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.6376 - acc: 0.7613 - val_loss: 0.9061 - val_acc: 0.6763\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.5960 - acc: 0.7727 - val_loss: 0.7957 - val_acc: 0.6912\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 100s 13s/step - loss: 0.5883 - acc: 0.7735 - val_loss: 0.8053 - val_acc: 0.7237\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 100s 13s/step - loss: 0.5866 - acc: 0.7800 - val_loss: 0.8201 - val_acc: 0.7125\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.6004 - acc: 0.7617 - val_loss: 0.7755 - val_acc: 0.7112\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.5698 - acc: 0.7876 - val_loss: 0.8382 - val_acc: 0.7025\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.5422 - acc: 0.7861 - val_loss: 0.8505 - val_acc: 0.6962\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 103s 13s/step - loss: 0.5243 - acc: 0.7959 - val_loss: 0.9490 - val_acc: 0.6825\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.5659 - acc: 0.7845 - val_loss: 0.9168 - val_acc: 0.6738\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 103s 13s/step - loss: 0.5386 - acc: 0.8023 - val_loss: 0.9262 - val_acc: 0.6863\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.4951 - acc: 0.8165 - val_loss: 0.7729 - val_acc: 0.7375\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.4456 - acc: 0.8357 - val_loss: 0.8502 - val_acc: 0.7313\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.4311 - acc: 0.8353 - val_loss: 0.9109 - val_acc: 0.7275\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.4315 - acc: 0.8493 - val_loss: 0.7806 - val_acc: 0.7350\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.3967 - acc: 0.8596 - val_loss: 0.9329 - val_acc: 0.7188\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 100s 13s/step - loss: 0.4025 - acc: 0.8486 - val_loss: 0.8581 - val_acc: 0.7562\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 106s 13s/step - loss: 0.3526 - acc: 0.8741 - val_loss: 0.8600 - val_acc: 0.7225\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.3221 - acc: 0.8829 - val_loss: 0.9063 - val_acc: 0.7150\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.3380 - acc: 0.8790 - val_loss: 0.9319 - val_acc: 0.7275\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 103s 13s/step - loss: 0.3148 - acc: 0.8809 - val_loss: 0.8708 - val_acc: 0.7050\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.2799 - acc: 0.8954 - val_loss: 1.0744 - val_acc: 0.6838\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.3033 - acc: 0.8910 - val_loss: 0.8840 - val_acc: 0.7312\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.2669 - acc: 0.9035 - val_loss: 0.9889 - val_acc: 0.6987\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.2890 - acc: 0.8973 - val_loss: 1.0166 - val_acc: 0.7125\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.2418 - acc: 0.9126 - val_loss: 1.0307 - val_acc: 0.7287\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 105s 13s/step - loss: 0.2399 - acc: 0.9184 - val_loss: 1.0533 - val_acc: 0.7037\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 101s 13s/step - loss: 0.2318 - acc: 0.9189 - val_loss: 0.9867 - val_acc: 0.7313\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.2108 - acc: 0.9234 - val_loss: 1.0651 - val_acc: 0.7137\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 102s 13s/step - loss: 0.2237 - acc: 0.9231 - val_loss: 1.2239 - val_acc: 0.6525\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 100s 13s/step - loss: 0.2041 - acc: 0.9273 - val_loss: 1.0302 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ad04db6e80>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch= 3523 // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=800  // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
