{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo vamos a implementar una CNN que permita clasificacion multiclase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso es crear 2 carpetas que son: la carpeta de entrenamiento y la carpeta de pruebas; luego dentro de cada una de ellas se deben ubicar N carpetas que denotan cada una de las clases, y dentro de cada una de estas carpetas deben  contener las respectivas imagenes correspondientes a la clase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![folder_data](img/folder_data.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras tiene una clase llamada ImageDataGenerator que permite hacer aumentos en tiempo real de las imagenes.En este ejmplo vamos a utilizar el metodo flow_from_directory()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es muy importante resaltar que el metodo flow_from_directory() espera una estructura similar a la que se presentan en la figura anterior para su correcto funcionamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los nombres de las carpetas para las clases son importantes, nombrarlas (o renombrarlas) con los nombres de las etiquetas respectivas para que sea más fácil para usted más tarde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso es crear una instancia de la clase ImageDataGenerator con algunas configuraciones basicas, como rotacion de 40 grados de la imagen, normalizacion de la imagen, acercamiento aleatorio de la imagen entre otros opciones disponibles para su consulta en el siguiente enlace:https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 3000\n",
    "nb_validation_samples = 320\n",
    "epochs = 50\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTRENAMIENTO_DIR = 'data/data/entrenamiento/'\n",
    "TEST_DIR = 'data/data/pruebas/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion se presenta la siguiente instruccion con los parametros comunmente utilizados para flow_from_directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2002 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=ENTRENAMIENTO_DIR,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- directory: ruta donde se encuentran las imagenes.\n",
    "- target_size: las imagenes de entrada sera redimenzionadas al tamaño que determine.\n",
    "- color_mode: si la imagen es en escala de grises colocar \"grayscale\", si es a color \"rgb\"\n",
    "- batch_size: numero de imagenes que se procesaran por el generador de lotes.\n",
    "- class_mode: si es un problema binario configure \"binary\", si es multi clases configure \"categorical\"\n",
    "- shuffle: configure True, si desea barajar las imagenes, de lo contrario configure False.\n",
    "- seed: Semilla aleatoria para aplicar un aumento de imagen aleatorio y barajar el orden de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igual paso para las imagenes de pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso anterior se configuro class_mode como None, porque solo requerimos que nos retorne las imagenes. En el caso de shuffle establezca esta opción en False, ya que necesita producir las imágenes en \"orden\", para predecir las salidas y hacerlas coincidir con sus ids o nombres de archivo únicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\jhovanny\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\jhovanny\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo entrenaremos la CNN para clasificacion multiclase, para lo cual utilizaremos el siguiente dataset disponible en Kaggle: https://www.kaggle.com/jutrera/stanford-car-dataset-by-classes-folder/downloads/stanford-car-dataset-by-classes-folder.zip/2.<br>\n",
    "Las modificaciones que debemos realizar es configurar la perdidad como categorical_crossentropy y el parametro class_mode del metodo flow_from_directory en categorical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer paso definimos las rutas de la carpeta donde se encuentran ubicadas las imagenes, es importante respetar la estructura de carpetas para que el metodo flow_from_directory puede funcionar correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTRENAMIENTO_DIR = 'data/flowers/train/'\n",
    "TEST_DIR = 'data/flowers/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3523 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=ENTRENAMIENTO_DIR,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 34, 34, 96)        55392     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 34, 34, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 17, 17, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 128)       110720    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 2565      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 3,399,845\n",
      "Trainable params: 3,399,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(96, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\jhovanny\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "440/440 [==============================] - 68s 154ms/step - loss: 1.2889 - acc: 0.4457 - val_loss: 1.0141 - val_acc: 0.5675\n",
      "Epoch 2/50\n",
      "440/440 [==============================] - 68s 156ms/step - loss: 1.0242 - acc: 0.5878 - val_loss: 0.9548 - val_acc: 0.6050\n",
      "Epoch 3/50\n",
      "440/440 [==============================] - 91s 207ms/step - loss: 0.9218 - acc: 0.6463 - val_loss: 0.8372 - val_acc: 0.6750\n",
      "Epoch 4/50\n",
      "440/440 [==============================] - 81s 184ms/step - loss: 0.8524 - acc: 0.6771 - val_loss: 0.9824 - val_acc: 0.6275\n",
      "Epoch 5/50\n",
      "440/440 [==============================] - 74s 168ms/step - loss: 0.8010 - acc: 0.6899 - val_loss: 0.8748 - val_acc: 0.6625\n",
      "Epoch 6/50\n",
      "440/440 [==============================] - 73s 166ms/step - loss: 0.7412 - acc: 0.7156 - val_loss: 0.8650 - val_acc: 0.6650\n",
      "Epoch 7/50\n",
      "440/440 [==============================] - 64s 146ms/step - loss: 0.6630 - acc: 0.7527 - val_loss: 0.8609 - val_acc: 0.6775\n",
      "Epoch 8/50\n",
      "440/440 [==============================] - 64s 146ms/step - loss: 0.6351 - acc: 0.7559 - val_loss: 0.8974 - val_acc: 0.6800\n",
      "Epoch 9/50\n",
      "440/440 [==============================] - 65s 147ms/step - loss: 0.6008 - acc: 0.7678 - val_loss: 0.8005 - val_acc: 0.6987\n",
      "Epoch 10/50\n",
      "440/440 [==============================] - 64s 145ms/step - loss: 0.5216 - acc: 0.7992 - val_loss: 0.8113 - val_acc: 0.7225\n",
      "Epoch 11/50\n",
      "440/440 [==============================] - 59s 133ms/step - loss: 0.4999 - acc: 0.8086 - val_loss: 0.9252 - val_acc: 0.7113\n",
      "Epoch 12/50\n",
      "440/440 [==============================] - 59s 134ms/step - loss: 0.4441 - acc: 0.8339 - val_loss: 0.8821 - val_acc: 0.7087\n",
      "Epoch 13/50\n",
      "440/440 [==============================] - 62s 140ms/step - loss: 0.3936 - acc: 0.8541 - val_loss: 0.9540 - val_acc: 0.6925\n",
      "Epoch 14/50\n",
      "440/440 [==============================] - 60s 137ms/step - loss: 0.3814 - acc: 0.8680 - val_loss: 0.8734 - val_acc: 0.7137\n",
      "Epoch 15/50\n",
      "440/440 [==============================] - 61s 138ms/step - loss: 0.3280 - acc: 0.8793 - val_loss: 1.2331 - val_acc: 0.6637\n",
      "Epoch 16/50\n",
      "440/440 [==============================] - 62s 141ms/step - loss: 0.3007 - acc: 0.8953 - val_loss: 1.0260 - val_acc: 0.7050\n",
      "Epoch 17/50\n",
      "440/440 [==============================] - 61s 139ms/step - loss: 0.2972 - acc: 0.8920 - val_loss: 1.0632 - val_acc: 0.7063\n",
      "Epoch 18/50\n",
      "440/440 [==============================] - 65s 147ms/step - loss: 0.2706 - acc: 0.9049 - val_loss: 1.0119 - val_acc: 0.6987\n",
      "Epoch 19/50\n",
      "440/440 [==============================] - 60s 137ms/step - loss: 0.2551 - acc: 0.9098 - val_loss: 1.1334 - val_acc: 0.7212\n",
      "Epoch 20/50\n",
      "440/440 [==============================] - 60s 136ms/step - loss: 0.1935 - acc: 0.9330 - val_loss: 1.3953 - val_acc: 0.6925\n",
      "Epoch 21/50\n",
      "440/440 [==============================] - 62s 140ms/step - loss: 0.2087 - acc: 0.9349 - val_loss: 1.1321 - val_acc: 0.7250\n",
      "Epoch 22/50\n",
      "440/440 [==============================] - 76s 172ms/step - loss: 0.1754 - acc: 0.9437 - val_loss: 1.4634 - val_acc: 0.7050\n",
      "Epoch 23/50\n",
      "440/440 [==============================] - 68s 155ms/step - loss: 0.1892 - acc: 0.9361 - val_loss: 1.4137 - val_acc: 0.7087\n",
      "Epoch 24/50\n",
      "440/440 [==============================] - 66s 151ms/step - loss: 0.1677 - acc: 0.9423 - val_loss: 1.3424 - val_acc: 0.7025\n",
      "Epoch 25/50\n",
      "440/440 [==============================] - 61s 139ms/step - loss: 0.1670 - acc: 0.9432 - val_loss: 1.3000 - val_acc: 0.7163\n",
      "Epoch 26/50\n",
      "440/440 [==============================] - 67s 153ms/step - loss: 0.1612 - acc: 0.9469 - val_loss: 1.5833 - val_acc: 0.6987\n",
      "Epoch 27/50\n",
      "440/440 [==============================] - 73s 165ms/step - loss: 0.1470 - acc: 0.9503 - val_loss: 1.5590 - val_acc: 0.7000\n",
      "Epoch 28/50\n",
      "440/440 [==============================] - 61s 139ms/step - loss: 0.1565 - acc: 0.9509 - val_loss: 1.3876 - val_acc: 0.6950\n",
      "Epoch 29/50\n",
      "440/440 [==============================] - 59s 135ms/step - loss: 0.1509 - acc: 0.9526 - val_loss: 1.4120 - val_acc: 0.7125\n",
      "Epoch 30/50\n",
      "440/440 [==============================] - 65s 148ms/step - loss: 0.1321 - acc: 0.9574 - val_loss: 1.6038 - val_acc: 0.7100\n",
      "Epoch 31/50\n",
      "440/440 [==============================] - 63s 142ms/step - loss: 0.1308 - acc: 0.9577 - val_loss: 1.4356 - val_acc: 0.7125\n",
      "Epoch 32/50\n",
      "440/440 [==============================] - 60s 136ms/step - loss: 0.1246 - acc: 0.9598 - val_loss: 1.4142 - val_acc: 0.7225\n",
      "Epoch 33/50\n",
      "440/440 [==============================] - 59s 134ms/step - loss: 0.1211 - acc: 0.9699 - val_loss: 1.5559 - val_acc: 0.7150\n",
      "Epoch 34/50\n",
      "440/440 [==============================] - 59s 134ms/step - loss: 0.1002 - acc: 0.9648 - val_loss: 1.6337 - val_acc: 0.7037\n",
      "Epoch 35/50\n",
      "440/440 [==============================] - 59s 134ms/step - loss: 0.1519 - acc: 0.9534 - val_loss: 1.4834 - val_acc: 0.7100\n",
      "Epoch 36/50\n",
      "440/440 [==============================] - 58s 133ms/step - loss: 0.1231 - acc: 0.9651 - val_loss: 1.5331 - val_acc: 0.7150\n",
      "Epoch 37/50\n",
      "440/440 [==============================] - 59s 134ms/step - loss: 0.0978 - acc: 0.9739 - val_loss: 1.4874 - val_acc: 0.7225\n",
      "Epoch 38/50\n",
      "440/440 [==============================] - 59s 133ms/step - loss: 0.1053 - acc: 0.9653 - val_loss: 1.6338 - val_acc: 0.7188\n",
      "Epoch 39/50\n",
      "440/440 [==============================] - 59s 134ms/step - loss: 0.1120 - acc: 0.9670 - val_loss: 1.7977 - val_acc: 0.6987\n",
      "Epoch 40/50\n",
      "440/440 [==============================] - 59s 135ms/step - loss: 0.1066 - acc: 0.9679 - val_loss: 1.7935 - val_acc: 0.7100\n",
      "Epoch 41/50\n",
      "440/440 [==============================] - 59s 134ms/step - loss: 0.1051 - acc: 0.9673 - val_loss: 1.5414 - val_acc: 0.7113\n",
      "Epoch 42/50\n",
      "440/440 [==============================] - 59s 134ms/step - loss: 0.0854 - acc: 0.9719 - val_loss: 1.6184 - val_acc: 0.7075\n",
      "Epoch 43/50\n",
      "440/440 [==============================] - 59s 134ms/step - loss: 0.0726 - acc: 0.9744 - val_loss: 1.8445 - val_acc: 0.7212\n",
      "Epoch 44/50\n",
      "440/440 [==============================] - 59s 134ms/step - loss: 0.0974 - acc: 0.9705 - val_loss: 2.0553 - val_acc: 0.7013\n",
      "Epoch 45/50\n",
      "440/440 [==============================] - 58s 132ms/step - loss: 0.1134 - acc: 0.9642 - val_loss: 1.9672 - val_acc: 0.6963\n",
      "Epoch 46/50\n",
      "440/440 [==============================] - 61s 138ms/step - loss: 0.1028 - acc: 0.9676 - val_loss: 1.8463 - val_acc: 0.7150\n",
      "Epoch 47/50\n",
      "440/440 [==============================] - 60s 136ms/step - loss: 0.0840 - acc: 0.9756 - val_loss: 1.7309 - val_acc: 0.7063\n",
      "Epoch 48/50\n",
      "440/440 [==============================] - 59s 133ms/step - loss: 0.1420 - acc: 0.9582 - val_loss: 1.7525 - val_acc: 0.6937\n",
      "Epoch 49/50\n",
      "440/440 [==============================] - 59s 134ms/step - loss: 0.0975 - acc: 0.9727 - val_loss: 2.1079 - val_acc: 0.6963\n",
      "Epoch 50/50\n",
      "440/440 [==============================] - 59s 134ms/step - loss: 0.1257 - acc: 0.9628 - val_loss: 1.8242 - val_acc: 0.7150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2219f08e940>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch= 3523 // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=800  // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
